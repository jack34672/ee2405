{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of EE2405_Exam_2_Part_2_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI1ebUOX16FD",
        "colab_type": "text"
      },
      "source": [
        "# EE2405 Embedded System Lab Exam #2 Part 2\n",
        "\n",
        "**Please click on \"Open in playground\" at the upper-left corner to create a copy for you.**\n",
        "\n",
        "---\n",
        "\n",
        "**Please fill in correct statements in the right of the codes to finish the scripts.**  \n",
        "Data sample is generated with a quadratic function and we will train a regression model to fit the data.  \n",
        "And we convert and interpret the trained model with a Tensorflow lite APIs.\n",
        "\n",
        "You can run the script again after you fill all the blank to check the outputs.\n",
        "\n",
        "---\n",
        "\n",
        "The Method to Download the Jupyter Notebook:  \n",
        "File > Download .ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC3FqFF1zRJW",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhRpD2SsyQrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow is an open source machine learning library\n",
        "import tensorflow as tf\n",
        "# Numpy is a math library\n",
        "import numpy as np\n",
        "# Matplotlib is a graphing library\n",
        "import matplotlib.pyplot as plt\n",
        "# math is Python's math library\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YztOxOMy0eUB",
        "colab_type": "text"
      },
      "source": [
        "## Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgApv0fcwU3I",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "a51ad0e5-a740-4d06-ca59-e4828aac2e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# We'll generate this many sample datapoints\n",
        "############################################################\n",
        "#@markdown Please fill in the number of samples (the sample should be large enough, but not too large for computation).\n",
        "SAMPLES =  200#@param {type:\"number\"}\n",
        "############################################################\n",
        "\n",
        "\n",
        "############################################################\n",
        "#@markdown Please fill in your student id, which is the random seed.\n",
        "student_id = 1060601146 #@param {type:\"number\"}\n",
        "np.random.seed(student_id)\n",
        "############################################################\n",
        "\n",
        "# Generate a uniformly distributed set of random numbers\n",
        "# in the range from 0 to 10\n",
        "x_values = np.random.uniform(low=0, high=10, size=SAMPLES)\n",
        "\n",
        "# Shuffle the values to guarantee they're not in order\n",
        "np.random.shuffle(x_values)\n",
        "\n",
        "############################################################\n",
        "#@markdown Please fill in the statement to generate `y_values` with a quadratic function `y = x^2-5x+1`?\n",
        "script = \"y_values = np.array([x * x - 5*x + 1 for x in x_values])\" #@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################\n",
        "\n",
        "# Plot our data.\n",
        "# The 'b.' argument tells the library to print blue dots.\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGVnrxG10nHh",
        "colab_type": "text"
      },
      "source": [
        "## Add some noise\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR7y-_3_x-Lz",
        "colab_type": "code",
        "outputId": "bdfb98be-f915-4ef1-97f7-04fe0b7fd1c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Add a small random number to each y value\n",
        "y_values += np.random.randn(*y_values.shape)\n",
        "\n",
        "# Plot our data\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAeWklEQVR4nO3dfZBc1Xnn8e/TMyPJcbaW9cACBsuiEpIUFZUtmFI86y17eLGDNzhSSikqzq5HC4olYswiOxsZbSW12nXKEJIK4wLb0dgS0VQImLVshBMnjpFnMFvqMowQXmIrKbMslmGRpUzw2ruFRqOZZ/84ferevuqe6Z7pt9v9+1RNdd/bb6dnpKdPP+c555i7IyIi+VNodwNERGR5FMBFRHJKAVxEJKcUwEVEckoBXEQkp/pb+WIXXnihr1u3rpUvKSKSe0ePHv1Hd78oe76lAXzdunVMT0+38iVFRHLPzL5f6bxSKCIiOaUALiKSUwrgIiI5pQAuIpJTCuAiIjlVUxWKmb0E/ASYB865+5CZvQn4ArAOeAm42d1fa04zRUQkq54e+LXu/nZ3Hyod3wUcdvcrgcOlYxERSSkW4e67w2WjraQOfBMwUrp+AJgCPr7C9oiIdIViESYmYP9+mJ+HVavg8GEYHm7ca9QawB34WzNzYK+7jwMXu/urpdtPAhc3rlkiIvlVLML118OZMxC3XDh7Fqam2hPA/7W7v2Jm/xL4upn9ffpGd/dScD+PmW0HtgOsXbt2RY0VEcmDqakQsGPwNgs98JGRxr5OTTlwd3+ldHkK+DKwEfihmV0aGmeXAqeqPHbc3Yfcfeiii86byi8i0nVGRkLA7uuD1athx47Gp0+ghh64mb0RKLj7T0rX3wv8V+BxYCtwT+nyUGObJiKST8PDIWBPTYVg3ujAHdWSQrkY+LKZxfv/hbv/jZk9AzxqZtuA7wM3N6eJIiL5MzzcvMAdLRnA3f1F4G0Vzs8A1zejUSIisjTNxBQRySkFcBGRJurUiTwiIrKIWA9+9mxzJvKoBy4i0iSxHnx+PpnI00gK4CIiTZKuB2/GRB6lUEREmqTZ9eAK4CIiTdTMenClUEREcko9cBGROsWlYgFGR5s/47IaBXARkRrFwL1vH8zNhXP79zd+mdhaKYCLiNSg0hrfEAJ5uwK4cuAiIjXIrvEd9fU1vjywVgrgIiI1iDXdYWHWxG/9Vvty4ArgIiI1iDXdmzaVnz95sjnrnNRCAVxEpEbDw3DJJeW98EOHQm68HUFcAVxEpEbFIjz4YHke3L0565zUQlUoIiJLiOWDzz6blA+aQaHUBW7GOie1UAAXEVlEsRiC89mzyblCIWxWPDYGMzPN3fdyMQrgIiKLmJpKet3RDTfAnj3tqz6JlAMXEVnEyAj0Z7q6W7a0P3iDAriIyKKGh2HbtuS4UIBjx5q3TVo9lEIREckoFsvX8B4dhQMHQh68vz+sfzI/35xt0uqhAC4iklJtH8u4McOJE/C5z5Vvk6aZmCIiHaDaPpbDw7B7d+iNN3ObtHqoBy4ikhLXPIk98GyAbvY2afVQABcRSaklQDdzm7R61BzAzawPmAZecfebzOwK4BFgEDgKfNDdzy72HCIinabS7jqdEqCXUk8O/E7geOr4D4H73P1ngdeAbRUfJSLSoYpFePe74U//NPyMjLS/NLAeNQVwM7sc+BXg86VjA64Dvli6ywFgczMaKCLSLPfeWz7Lcm4uzLDMSxCvtQc+BuwCFkrHg8CP3P1c6fhl4LIGt01EpGmKRfjKV8rPucMTT7Rvedh6LRnAzewm4JS7H13OC5jZdjObNrPp06dPL+cpREQabmrq/O3RzGBhoX3Lw9arlh74O4FfNbOXCIOW1wGfAi4wszgIejnwSqUHu/u4uw+5+9BFF13UgCaLiKzcyEhYUbBQCLMrd+2CNWs6o767VktWobj7bmA3gJmNAP/R3f+tmf034NcJQX0rcKiJ7RQRaahK5YKbN3dGfXetVlIH/nHgETP7A+AYsK8xTRIRaY1suWBeygejugK4u08BU6XrLwIbG98kERGphdZCERHJKQVwEZGcUgAXkZ5ULHbGpgwrocWsRKSrZTdniOdGRsLMy0IBPvMZ2L69jY1cJgVwEelacXOG2dlQ3/3AAyFQT0wku8zPz8OHPwzr1+erAgWUQhGRLjY1BWfOhNmVc3Nw++2VUyYLC/mYeZmlAC4iXWtwsHy6/Px8CNSjozAwkJwfGMjHzMsspVBEpGvNzIT1TWIQ7+tLcuFPPnn+OuB5owAuIl1rZCSsbxJz4B/9aPkel3kM2mkK4CLStdLrnQwOwh13hFz4wEB7d5NvFOXARaSrxd3kjx0LlSfu4TKmT/JMAVxEJKeUQhGRrhEn7QwOhgHM9OSd0VF48MHQ+161KhznnQK4iORWepYlJJN2FkqbP65eDZOTyYDl5GS+1vteigK4iORSnGUZe9Rbt4brMXhDCOYTE0mw7obKkzTlwEUkl6amQsCen0+mxa9a1dYmtZwCuIjk0shICNhxD8vRURgbC8fRwEB35LqrUQpFRHKp0p6W6fVMzGDbtu5KmWQpgItIbmVz2rFX3k2VJotRABeRrlGpV97NFMBFpKt0W6XJYjSIKSKSUwrgIiI5pQAuIpJTCuAikivdsJt8o2gQU0RyIzt9/vDh3hmwrEQ9cBHJjez0+TxuRNxISwZwM1tjZk+b2bfN7Dtm9l9K568ws2+Z2Qtm9gUz67FVCESk1bLT5/O4EXEj1dIDnwWuc/e3AW8HbjSzdwB/CNzn7j8LvAZsa14zRUSSiTqf+ITSJ1BDDtzdHfi/pcOB0o8D1wG/WTp/ANgDfLbxTRQRSfTSRJ2l1JQDN7M+M3sOOAV8HfifwI/c/VzpLi8Dl1V57HYzmzaz6dOnTzeizSLSQ1R1Ul1NVSjuPg+83cwuAL4M/EKtL+Du48A4wNDQkC+nkSLSm1R1sri6qlDc/UfAJDAMXGBm8QPgcuCVBrdNRHrcxAScOROqTs6c6Y6d5BupliqUi0o9b8zsDcB7gOOEQP7rpbttBQ41q5Ei0nuKxbAJsZe+t7uHY6VSErWkUC4FDphZHyHgP+ruf2lm3wUeMbM/AI4B+5rYThHpEXGj4qefTrZKi86dC7cpjRLUUoXyP4ANFc6/CGxsRqNEpDfFnHd6Z/moUFDtd5am0otIx4gzLdPB2ww2bYKNG3tjk4Z6KICLSMcYGQmzLOfnk3MDA7BrlwJ3JVoLRUTaLtZ6A9x6a+h1Q7i89VYF72rUAxeRtsrWeo+NwZo1vbMx8UoogItIW2VXGJyZ6a2NiVdCAVxE2iKWCw4Ohp527HHHoK3AvTQFcBFpuWza5I474LnnYMsWBe56KICLSMul0yazs3DffaF08KmnYP16BfFaqQpFRFpqfBweeyxMzOnrC5fz89plZzkUwEWkZcbHYceOME1+bg5+7ufgYx+D1au1y85yKIUiIi1z8GD58fHj8NJLoXRwZkZVJ/VSD1xEWmbLlvPPxdLB3bsVvOulHriItMz27eFy3z549tmwRKzSJsunAC4iTRdrvkdGQhDfvr38nHrey6MALiJNVW1bNE3WWTnlwEWkqdI136+/Djt3aledRlEAF5GmikvERk8/DddeqyDeCArgItIU2SVi0zRhpzGUAxeRhkkvULVzZ/kSsXHBKlDlSaMogItIQ6QHK83C2iYLC0md99QUTEyE+46OagCzERTARaQh0oOVcZ0TMy0R20wK4CKyYsUinDiRDFbGtImmxzeXAriIrEg6dVIowDXXhKCt4N18CuAisiLp1Mn8PDzzTCgVLBTCKoNx4o40nsoIRWRFRkZCyiTuJO8eLuMApsoFm0cBXESWJV3nffhwWOd79erQ84ZwqXLB5loyhWJmbwEmgIsBB8bd/VNm9ibgC8A64CXgZnd/rXlNFZFOUWl9k89+NpQHxjpw5cCbr5Yc+Dngd9z9WTP7Z8BRM/s68O+Bw+5+j5ndBdwFfLx5TRWRTpHOe8c0iRaoar0lUyju/qq7P1u6/hPgOHAZsAk4ULrbAWBzsxopIp0l5r21DVp71VWFYmbrgA3At4CL3f3V0k0nCSmWSo/ZDmwHWLt27XLbKSJtll2/+/BhrefdbjUHcDP7aeAgsNPdf2xxyBlwdzczr/Q4dx8HxgGGhoYq3kdEOttia3pL+9RUhWJmA4Tg/ZC7f6l0+odmdmnp9kuBU81pooi0WzbnPTERKlC0JGx71VKFYsA+4Li7/0nqpseBrcA9pctDTWmhiLRdzHnPzobjfftCnXe6Ny6tV0sP/J3AB4HrzOy50s+/IQTu95jZ94AbSsci0oWGh8PaJoVCCNxzc+UVKNIeS/bA3f2/A1bl5usb2xwR6VQzM2GWZZxpmV5pUNpDMzFFelycUblUPjtbOrhjh9In7abFrER6WLXqkmzJIKh0sBMpgIv0sHR1yews7NkDW7aUb4eW7mWrdLCzKICL9KD03pWxumRhAZ54AiYnQ0BfWIAzZ0LJoIJ2Z1IAF+kx2bTJ2BgcPBiC98JCMkgJ4fr+/drDslNpEFOkx2Qn5czMhNTJwEC4PV1pAnDunEoFO5UCuEiPidUkhUL4GRwMvetbbkk2ZUgzU6lgp1IAF+kx6Uk58/NhwLJYhA0bynve0vkUwEV6UJyUk972bGYm2U0nbX4+DGRK59EgpkgPimmUOJAZUyQDA8l6J9L51AMX6UFxUs6HPgRbtybnKuXBV60KVSjSeRTARXrYgQPwuc+FssJiMQTqNWuS6fK33ZZslyadRykUkR5VaV/L3bs1XT5PFMBFelCxCCdOhJ42lOfBNV0+PxTARXpMeiZmf3/Ig2umZT4pgIv0mHTqBGDtWgXvvNIgpkjO1bqed5Rd11uzLPNLPXCRHIvpkNnZEJAfeADWr198EFLrencPBXCRHJuaSpaCXViAD3845LXPnVt8w2ENVHYHpVBEcmxkJKkkgWRqvDYc7g0K4CI5Njwc0ib9/WEdk4EB5bd7iVIoIjmT3q8S4NgxuOkmuOSSUA74/PNhg4YtW5Qm6XYK4CI5kq3hXliAublw26pVYUnYuJ/lU0+FAU0F8e6lFIpIjmSnv8fgDeH6wYPKgfcSBXCRHMnuppMewBwYCGkT5cB7h1IoIjkSd9O5/fbQyy4U4F3vgquuSqbDL1UHLt1jyQBuZvuBm4BT7v6LpXNvAr4ArANeAm5299ea10wRgZADP3gwBG/3cHnkCNxzTxKsVePdO2pJofwZcGPm3F3AYXe/EjhcOhaRJooDmE88Ub535cKCct29askA7u7fBP4pc3oTcKB0/QCwucHtEpGMOIC5sJDkwAsFWL1aue5etdwc+MXu/mrp+kng4mp3NLPtwHaAtWvXLvPlRLpLupa71nRHdh/LsbGwEbFy3b1rxYOY7u5m5ovcPg6MAwwNDVW9n0ivKBbh2muTQDw5WVsA1iJUkrXcAP5DM7vU3V81s0uBU41slEg3m5hIdn6fnQ3H2WBcrYeuAUpJW24AfxzYCtxTujzUsBaJ9LhKS8Ru397uVkknWnIQ08weBorAz5vZy2a2jRC432Nm3wNuKB2LSA1GR0PqxCxcjo6W355eInZuLtR817pZg/SWJXvg7v6BKjdd3+C2iPSE4eEQpKvlsuMSsQsL4TiWCSp1IlmaiSnSBovlsuMSsbffHoK3ygSlGgVwkRZbrIQwfds3v6mKE1mcArhIC6WXg81ueVbptt2729te6WxajVCkhbLLwaanwC92m0glCuAiLRRnU1Za7nWx20QqUQpFpIUWm02pmZZSLwVwkRarVIGSHrxU3ltqpQAu0maLDWyKLEY5cJE20+ClLJcCuEiLFItw993nT4vX4KUsl1IoIi2wVJpk69ZwGfe1FKmFArhIC1RKkwwPnx/YswtbiSxGKRSRFRofh1/6Jfi1X0vSI9l0ycgI9PeHFQj7+5M0ifLfshLqgYssU7EI994Ljz2WnPurvwoLUd1xR1gKdmAgCcpxI+L0hsTZbdKU/5Z6KICLLENMfbz+evn5uTnYty8EZAiXO3fC1VeHXrZ7uIwpFE3ekZVQABepYrFVA+OmC1kDA/DmN5efe+YZ+Pa3Q5UJnN/T1jZpslwK4CIVLFU1MjIS8tlpb30rPPxwuP7Xf50EeHc4dw4+9CFYu1Y9bWkcBXCRCrKDixMT5b3x4WF4//vL89/ve18SmCcnw2P27w/PEStMFLilkczTIypNNjQ05NPT0y17PZHlSm8sbBZ+3Mt748UiXHtt0kufnKx9d3mRepjZUXcfyp5XD1ykguFhGBuDj3wkpD9iPyddww1wyy3hslrvWvltaSYFcJEqZmbCnpQxeMdd5EdGNAFHOoMm8ohUkZ58MzAAO3Yk6RNNwJFOoAAusoh07zudJtECVNIJlEIRqWJiIkzMyU6+AU3Akc6QywCukX1ptmIRHnww6YH39Z3fy9YApbRb7gK4di+RWqz0Q35qKlSfQEif3Hqr/p1J51lRDtzMbjSzfzCzF8zsrkY1ajHpwaPZWdiz5/wF8qW3xQ/53//9cLmcfx/pHPeaNaoykc607ABuZn3Ap4H3AVcBHzCzqxrVsGrif6xCIZR4PfHE8v+TSn5U282mknorRCo9d8xxf+IT+pYnnWslKZSNwAvu/iKAmT0CbAK+24iGVRP/Y+3ZE4L3wsL5kyuku9SbNqtnidbxcbj99vDvaPXq8udWjls63UpSKJcBP0gdv1w6V8bMtpvZtJlNnz59elkvlO4hxdzmli3hP9xSZVz19NykMy2n5nrr1rB41GLBvlhMZlouLISUnOq5JU+aPojp7uPAOIS1UOp9fLr31d+frOxWKMDHPgYXXFB9oEoDnt2hnh51PTMkp6bCh0JUKKieW/JlJT3wV4C3pI4vL51rqGzva24u9JbOnYP77js/eKd73Brw7B619Kihvt76yEj4FlcohJmWn/60PuAlX1bSA38GuNLMriAE7t8AfrMhrUpJ9776+0Pgjr2m7OSKbO9rbCxczs4mA55PPaWeeJ7Uu+ZIPb11TcaRvFt2D9zdzwEfAb4GHAcedffvNKphUboaYHISPvOZ0FsqFELvKf0fNNv7mpkJj73hhqRq5cyZMMMuTXnyzlVv/rve6pHhYdi9W8Fb8mlFOXB3/yrw1Qa1pap0NcDwMKxfX7nXlO599fXBiRPh/J498OSToSfuHioPTp6EXbvC7cqTd656N/0dH4eDB8Mgt/6O0vXcvWU/11xzjTfbkSPut93mvnq1e1+f+xvekJwL4Tv5WbUqnO/rC8d9fe6f/GTTmyhVHDkSfv9HjtR2Pmvv3vK/7969zWurSCsB014hpnbdaoTDw2HfwZgrj1+7R0dDDj1tbi5calW59hsfh3e/G37v95Y3MatYhD/6o/JzBw82rn0inSh3a6HUotLX7uHhUGXw278dcuEQcumjo7BhQ/K1G0I+PAbyxQa4sutttGuRrXYv7pV+fai/LcVimEwT1x6ZnU32oBwchJ07z09xZV/z+uvD+EZa/HuKdKuuDODVqgvWrw+98Lm5MKh5//3hfAwQTz6Z1JlX2wcxqlTxUinQNFu7a90r1enHTXzTbVnsw25qKvlQjcbHw3MVCuEyPeMWyt/z1q3hunv4m/3Mz8Dv/i5s396q34JIe3RlAIfK06DjxI24ROjMTHmVQ3r7rLRKU/Wz1REHD55fLVEteDVCfM4TJ6q/bitkf38QfofptoyPJzMe+/vh5pvh0UfDY1avDh9+q1cnGwin/w7z8yG9lU5xZX/3UP6Na2JCA5jSG7oygFcKmMViCHZ9feE4ne9O14pnZfdBjCWIGzaUB40tW0KNebZaohk95PRz9vUluf1qOfxmpljS6apYqhl/j08/naw1EtMjc3Pw0EPJ42dnw4ff2Fj4QD1xAvbuLX+N978fNm5M3lv27zg6Gn5Uzy29pusCeKXUxrFjsH9/6LH194cZfentsbKLY0ESuG+5JZk8cu21IeBAuO3++0PQiUGjUnljpTrmWgLMYkE3/ZwQ3s/atSFfHFMM6Q+ukZEQOAcG6uuhxzYMDpa/z7SYrpqYCL/j2Huen4fHHoOvfKXyB2MUJ1h94xtw9dXhNQYGkp71wEAo94xpl3S6Jvt3VOCWXtN1ATw7fT5+dU+nRtauLf/PPjwcetCTk+G4vz8s4J8ODnffnQQVCAFxZiZMAkk/TzaIDA4medxaq1yW6rVnB2njB0ylx0xMJO0+e7b29EJsQ/xmEj/QJicrp4bWri1PT0ULC6G3XOk2s+Q+Cwuhx/700yFg//jH4bb03yD7wZX9O4r0mq4L4OngZlYeONLpkLRiMQxAzs8ng5vZAbD4vLEHPjCwdDBOP68Z/PIv1/Yeluq1VxqkjR8w9fT0a+nlp/PasTok9obTPfv776+cioq3zcyE4HzoUDLYuGkTfO1r8Prr5a/93HPhfFa9k3pEul3XBfB0cEuXoPX3J+mQxYKVWQg2lZ53cjIEsJMn4ZJLlm5LNggeOhQCUyPXs670mP7+kCcuFkOuPvaA+/rCMSzdy4/fHNKr9aVle/bHjpX/3o8dC7elf9/FYnj/8TV37Qo/994b0i1RtfI/rV0iklFpdk+zfloxEzOrlll8R46EGZvpmZuNvK9ZMjuw1tmei7W7WhvijNP+/vCa/f1hRmp8bbPk/p/8ZPUZqPH5C4VwW19feOyqVclrbd5cPutx8+baZktWe19797q/972aPSlSCVVmYnZ9AK9VrdO1Fwt81Z73tttC8Fsq6DeiDZWWDEj/FArh/nv3hgBfKJzfpvTzFwruGzeG501/UKQ/GPr6zl+6QEQap1oA77oUynLVun1WvemN7HPGlEKliS3Z6plqlR+DgyHVUygs3YY4GSnq60tSS3GAcWys8iBpzGdPT8PzzyeDpVNT5Tu2X3MNHD3avlp0kV6lAF6nevOwldazLhZDSWI8NzlZuXpmYaHyjMZqwTeuHzIwEALsqlVw551h44tz58L9H3ggfDAslvNfat/R7IfYtm0hwGtwUaS1FMCXoZ7NbitVlJw4kVSzxMqO0dHyKpdY+pjt0VYbcM3WSO/YkfT2N28+v7e/1LeI4eEQwCtNTqr0IVZtiV8RaR4F8CarlHLJbigBIeiNjZXXrVdKkVRL4SxWI539wKn1W8Ri96v0nArcIq2lAN5k1YLg/v1JDXXMLc/MJDMZC4Wwk9CePbUF3+Xk5msJuArMIp3LvNLqTU0yNDTk09PTLXu9TlZtvZaVrJvS7mVlRaQ5zOyouw+dd14BvLMoCItIVrUArhRKh1HKQkRq1XVbqomI9AoFcBGRnFIAFxHJKQVwEZGcUgAXEckpBXARkZxqaR24mZ0Gvl/HQy4E/rFJzelUvfieQe+71+h91+et7n5R9mRLA3i9zGy6UvF6N+vF9wx63+1uR6vpfTeGUigiIjmlAC4iklOdHsDH292ANujF9wx6371G77sBOjoHLiIi1XV6D1xERKpQABcRyamODOBmdqOZ/YOZvWBmd7W7Pa1gZm8xs0kz+66ZfcfM7mx3m1rJzPrM7JiZ/WW729IqZnaBmX3RzP7ezI6bWU8sJGxmHy39G/87M3vYzNa0u03NYGb7zeyUmf1d6tybzOzrZva90uW/WMlrdFwAN7M+4NPA+4CrgA+Y2VXtbVVLnAN+x92vAt4B3N4j7zu6Ezje7ka02KeAv3H3XwDeRg+8fzO7DPgPwJC7/yLQB/xGe1vVNH8G3Jg5dxdw2N2vBA6Xjpet4wI4sBF4wd1fdPezwCPApja3qenc/VV3f7Z0/SeE/8yXtbdVrWFmlwO/Any+3W1pFTP758C7gH0A7n7W3X/U3la1TD/wBjPrB34K+N9tbk9TuPs3gX/KnN4EHChdPwBsXslrdGIAvwz4Qer4ZXokkEVmtg7YAHyrvS1pmTFgF7DQ7oa00BXAaeDBUuro82b2xnY3qtnc/RXgj4ETwKvA/3H3v21vq1rqYnd/tXT9JHDxSp6sEwN4TzOznwYOAjvd/cftbk+zmdlNwCl3P9rutrRYP3A18Fl33wD8P1b4dToPSjnfTYQPsDcDbzSzf9feVrWHhxruFdVxd2IAfwV4S+r48tK5rmdmA4Tg/ZC7f6nd7WmRdwK/amYvEdJl15nZn7e3SS3xMvCyu8dvWV8kBPRudwPwv9z9tLvPAV8C/lWb29RKPzSzSwFKl6dW8mSdGMCfAa40syvMbBVhgOPxNrep6czMCPnQ4+7+J+1uT6u4+253v9zd1xH+1t9w967vkbn7SeAHZvbzpVPXA99tY5Na5QTwDjP7qdK/+evpgcHblMeBraXrW4FDK3myjtuV3t3PmdlHgK8RRqj3u/t32tysVngn8EHgeTN7rnTuP7n7V9vYJmmuO4CHSh2VF4Fb2tyepnP3b5nZF4FnCZVXx+jSafVm9jAwAlxoZi8D/xm4B3jUzLYRlta+eUWvoan0IiL51IkpFBERqYECuIhITimAi4jklAK4iEhOKYCLiOSUAriISE4pgIuI5NT/B+hLGNeEni8nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI4ZI4Wv4B_y",
        "colab_type": "text"
      },
      "source": [
        "## Split our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1zguEyz393e",
        "colab_type": "code",
        "outputId": "fd62f2d6-f874-4a58-ab46-a84cdac32050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# We'll use 60% of our data for training and 20% for testing. The remaining 20%\n",
        "# will be used for validation. Calculate the indices of each section.\n",
        "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "\n",
        "# Use np.split to chop our data into three parts.\n",
        "# The second argument to np.split is an array of indices where the data will be\n",
        "# split. We provide two indices, so the data will be divided into three chunks.\n",
        "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "# Double check that our splits add up correctly\n",
        "assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES\n",
        "\n",
        "# Plot the data in each partition in different colors:\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JggfIuHp4PCy",
        "colab_type": "text"
      },
      "source": [
        "## Design a model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nty9IWi-4QhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll use Keras to create a simple model architecture\n",
        "from tensorflow.keras import layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# First layer takes a scalar input and feeds it through 16 \"neurons\". The\n",
        "# neurons decide whether to activate based on the 'relu' activation function.\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "\n",
        "# The new second layer may help the network learn more complex representations\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "\n",
        "# Final layer is a single neuron, since we want to output a single value\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "# Compile the model using a standard optimizer and loss function for regression\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMeLOUmx4VY7",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJiV9Aee4ZTb",
        "colab_type": "code",
        "outputId": "d798c69a-bf41-4dae-bf1a-1bf5ddec1452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model on our training data while validating on our validation set\n",
        "model.fit(x_train, y_train, epochs=1000, batch_size=16,\n",
        "          validation_data=(x_validate, y_validate))\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 398.5940 - mae: 14.0462 - val_loss: 415.2996 - val_mae: 13.9238\n",
            "Epoch 2/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 362.7767 - mae: 13.6679 - val_loss: 395.9016 - val_mae: 13.6945\n",
            "Epoch 3/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 340.0768 - mae: 13.3865 - val_loss: 378.2226 - val_mae: 13.4759\n",
            "Epoch 4/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 338.6509 - mae: 13.1252 - val_loss: 359.6370 - val_mae: 13.2528\n",
            "Epoch 5/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 312.3264 - mae: 12.8500 - val_loss: 344.1656 - val_mae: 13.0824\n",
            "Epoch 6/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 296.3443 - mae: 12.6304 - val_loss: 329.4614 - val_mae: 12.9232\n",
            "Epoch 7/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 285.7544 - mae: 12.4133 - val_loss: 316.0458 - val_mae: 12.7775\n",
            "Epoch 8/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 269.9490 - mae: 12.2353 - val_loss: 302.1240 - val_mae: 12.6202\n",
            "Epoch 9/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 264.1395 - mae: 12.0539 - val_loss: 287.8204 - val_mae: 12.4525\n",
            "Epoch 10/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 256.7505 - mae: 11.8852 - val_loss: 273.6156 - val_mae: 12.2776\n",
            "Epoch 11/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 239.8589 - mae: 11.6914 - val_loss: 259.4720 - val_mae: 12.0941\n",
            "Epoch 12/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 232.1955 - mae: 11.5259 - val_loss: 245.9478 - val_mae: 11.9082\n",
            "Epoch 13/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 215.5708 - mae: 11.3829 - val_loss: 233.6324 - val_mae: 11.7275\n",
            "Epoch 14/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 218.2027 - mae: 11.2089 - val_loss: 219.8225 - val_mae: 11.5112\n",
            "Epoch 15/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 198.9320 - mae: 11.0028 - val_loss: 207.8100 - val_mae: 11.3067\n",
            "Epoch 16/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 183.3679 - mae: 10.8939 - val_loss: 198.0099 - val_mae: 11.1498\n",
            "Epoch 17/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 187.7130 - mae: 10.7302 - val_loss: 186.6649 - val_mae: 10.9596\n",
            "Epoch 18/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 166.9295 - mae: 10.6565 - val_loss: 179.4250 - val_mae: 10.8451\n",
            "Epoch 19/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 178.4370 - mae: 10.5372 - val_loss: 169.7735 - val_mae: 10.6870\n",
            "Epoch 20/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 151.0680 - mae: 10.4602 - val_loss: 163.8229 - val_mae: 10.5743\n",
            "Epoch 21/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 155.1504 - mae: 10.3904 - val_loss: 156.9939 - val_mae: 10.4342\n",
            "Epoch 22/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 146.7921 - mae: 10.3597 - val_loss: 152.1830 - val_mae: 10.3464\n",
            "Epoch 23/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 141.9787 - mae: 10.3138 - val_loss: 147.6942 - val_mae: 10.2735\n",
            "Epoch 24/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 139.0014 - mae: 10.3130 - val_loss: 144.4266 - val_mae: 10.2127\n",
            "Epoch 25/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 140.2610 - mae: 10.2918 - val_loss: 141.1452 - val_mae: 10.1493\n",
            "Epoch 26/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 133.5458 - mae: 10.3217 - val_loss: 140.0684 - val_mae: 10.1220\n",
            "Epoch 27/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 131.7112 - mae: 10.2794 - val_loss: 138.5858 - val_mae: 10.0936\n",
            "Epoch 28/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 137.2739 - mae: 10.2602 - val_loss: 136.2404 - val_mae: 10.0543\n",
            "Epoch 29/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 132.7072 - mae: 10.2666 - val_loss: 135.2433 - val_mae: 10.0199\n",
            "Epoch 30/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 129.7465 - mae: 10.2228 - val_loss: 134.1060 - val_mae: 9.9883\n",
            "Epoch 31/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 129.9053 - mae: 10.2452 - val_loss: 133.5566 - val_mae: 9.9606\n",
            "Epoch 32/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 129.3479 - mae: 10.2399 - val_loss: 132.9394 - val_mae: 9.9343\n",
            "Epoch 33/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 129.9955 - mae: 10.1821 - val_loss: 131.7813 - val_mae: 9.9005\n",
            "Epoch 34/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 131.7153 - mae: 10.1896 - val_loss: 131.0051 - val_mae: 9.8683\n",
            "Epoch 35/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 128.3247 - mae: 10.1760 - val_loss: 130.4482 - val_mae: 9.8391\n",
            "Epoch 36/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 127.1249 - mae: 10.1082 - val_loss: 129.4325 - val_mae: 9.8108\n",
            "Epoch 37/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 127.0464 - mae: 10.1420 - val_loss: 128.5630 - val_mae: 9.7828\n",
            "Epoch 38/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 128.2551 - mae: 10.1244 - val_loss: 128.2338 - val_mae: 9.7581\n",
            "Epoch 39/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 125.9226 - mae: 10.0679 - val_loss: 127.4720 - val_mae: 9.7330\n",
            "Epoch 40/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 125.1283 - mae: 10.0630 - val_loss: 127.1175 - val_mae: 9.7007\n",
            "Epoch 41/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 123.0683 - mae: 10.0408 - val_loss: 126.8137 - val_mae: 9.6712\n",
            "Epoch 42/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 122.4599 - mae: 10.0123 - val_loss: 126.4777 - val_mae: 9.6414\n",
            "Epoch 43/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 123.7064 - mae: 10.0060 - val_loss: 126.0039 - val_mae: 9.6142\n",
            "Epoch 44/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 120.9735 - mae: 9.9441 - val_loss: 125.5292 - val_mae: 9.5897\n",
            "Epoch 45/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 121.0810 - mae: 9.9216 - val_loss: 125.0131 - val_mae: 9.5627\n",
            "Epoch 46/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 126.2433 - mae: 9.8838 - val_loss: 123.9948 - val_mae: 9.5393\n",
            "Epoch 47/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 125.9888 - mae: 9.8853 - val_loss: 123.2722 - val_mae: 9.5098\n",
            "Epoch 48/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 123.9857 - mae: 9.8764 - val_loss: 122.7219 - val_mae: 9.4820\n",
            "Epoch 49/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 121.4482 - mae: 9.8555 - val_loss: 122.4200 - val_mae: 9.4514\n",
            "Epoch 50/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 117.8232 - mae: 9.8201 - val_loss: 122.1684 - val_mae: 9.4200\n",
            "Epoch 51/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 122.0242 - mae: 9.7713 - val_loss: 121.2771 - val_mae: 9.3897\n",
            "Epoch 52/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 123.6630 - mae: 9.7642 - val_loss: 120.3996 - val_mae: 9.3597\n",
            "Epoch 53/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 118.4053 - mae: 9.7601 - val_loss: 119.9324 - val_mae: 9.3255\n",
            "Epoch 54/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 117.5992 - mae: 9.7134 - val_loss: 119.1494 - val_mae: 9.2968\n",
            "Epoch 55/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 117.2388 - mae: 9.6891 - val_loss: 118.5837 - val_mae: 9.2666\n",
            "Epoch 56/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 116.6457 - mae: 9.6849 - val_loss: 118.3797 - val_mae: 9.2337\n",
            "Epoch 57/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 116.0470 - mae: 9.6268 - val_loss: 117.8031 - val_mae: 9.2064\n",
            "Epoch 58/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 116.1980 - mae: 9.6013 - val_loss: 117.4117 - val_mae: 9.1744\n",
            "Epoch 59/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 113.4112 - mae: 9.5694 - val_loss: 116.8393 - val_mae: 9.1446\n",
            "Epoch 60/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 115.4252 - mae: 9.5428 - val_loss: 116.1469 - val_mae: 9.1128\n",
            "Epoch 61/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 112.9727 - mae: 9.5228 - val_loss: 115.4926 - val_mae: 9.0801\n",
            "Epoch 62/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 112.7682 - mae: 9.4921 - val_loss: 114.8089 - val_mae: 9.0466\n",
            "Epoch 63/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 112.0955 - mae: 9.4727 - val_loss: 114.1170 - val_mae: 9.0111\n",
            "Epoch 64/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 115.2655 - mae: 9.4489 - val_loss: 113.2007 - val_mae: 8.9773\n",
            "Epoch 65/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 111.2010 - mae: 9.4154 - val_loss: 112.5969 - val_mae: 8.9433\n",
            "Epoch 66/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 114.0904 - mae: 9.4088 - val_loss: 111.8965 - val_mae: 8.9046\n",
            "Epoch 67/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 110.7205 - mae: 9.3957 - val_loss: 111.8109 - val_mae: 8.8717\n",
            "Epoch 68/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 112.3214 - mae: 9.3615 - val_loss: 111.5548 - val_mae: 8.8430\n",
            "Epoch 69/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 108.2518 - mae: 9.2713 - val_loss: 111.0652 - val_mae: 8.8160\n",
            "Epoch 70/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 107.2142 - mae: 9.2473 - val_loss: 110.5284 - val_mae: 8.7876\n",
            "Epoch 71/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 111.1526 - mae: 9.2049 - val_loss: 109.3748 - val_mae: 8.7559\n",
            "Epoch 72/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 107.4372 - mae: 9.2223 - val_loss: 109.0382 - val_mae: 8.7215\n",
            "Epoch 73/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 105.4990 - mae: 9.1807 - val_loss: 108.2446 - val_mae: 8.6835\n",
            "Epoch 74/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 105.4012 - mae: 9.1393 - val_loss: 107.3994 - val_mae: 8.6446\n",
            "Epoch 75/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 105.7686 - mae: 9.1454 - val_loss: 106.6502 - val_mae: 8.6110\n",
            "Epoch 76/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 105.9915 - mae: 9.0991 - val_loss: 106.3292 - val_mae: 8.5763\n",
            "Epoch 77/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 104.2133 - mae: 9.0394 - val_loss: 105.7521 - val_mae: 8.5405\n",
            "Epoch 78/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 103.6546 - mae: 9.0062 - val_loss: 104.8372 - val_mae: 8.5051\n",
            "Epoch 79/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 100.1346 - mae: 9.0029 - val_loss: 104.3932 - val_mae: 8.4739\n",
            "Epoch 80/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 102.8606 - mae: 8.9475 - val_loss: 103.6784 - val_mae: 8.4410\n",
            "Epoch 81/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 100.5568 - mae: 8.9212 - val_loss: 102.9704 - val_mae: 8.4065\n",
            "Epoch 82/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 101.6740 - mae: 8.8813 - val_loss: 102.3383 - val_mae: 8.3700\n",
            "Epoch 83/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 98.3366 - mae: 8.8738 - val_loss: 101.6304 - val_mae: 8.3358\n",
            "Epoch 84/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 100.7522 - mae: 8.8278 - val_loss: 100.9516 - val_mae: 8.3004\n",
            "Epoch 85/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 96.6815 - mae: 8.7659 - val_loss: 100.3243 - val_mae: 8.2673\n",
            "Epoch 86/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 100.7334 - mae: 8.7530 - val_loss: 99.5016 - val_mae: 8.2292\n",
            "Epoch 87/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 97.9967 - mae: 8.7114 - val_loss: 98.5404 - val_mae: 8.1873\n",
            "Epoch 88/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 95.3344 - mae: 8.6932 - val_loss: 97.8551 - val_mae: 8.1496\n",
            "Epoch 89/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 95.7989 - mae: 8.6621 - val_loss: 97.2946 - val_mae: 8.1152\n",
            "Epoch 90/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 92.8087 - mae: 8.6080 - val_loss: 96.5214 - val_mae: 8.0778\n",
            "Epoch 91/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 94.3266 - mae: 8.5642 - val_loss: 95.7270 - val_mae: 8.0357\n",
            "Epoch 92/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 96.6565 - mae: 8.5531 - val_loss: 95.0437 - val_mae: 7.9951\n",
            "Epoch 93/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 94.2818 - mae: 8.4970 - val_loss: 93.8950 - val_mae: 7.9525\n",
            "Epoch 94/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 90.5094 - mae: 8.4650 - val_loss: 93.0987 - val_mae: 7.9199\n",
            "Epoch 95/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 93.8790 - mae: 8.4387 - val_loss: 92.3129 - val_mae: 7.8739\n",
            "Epoch 96/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 90.7799 - mae: 8.4013 - val_loss: 91.4145 - val_mae: 7.8380\n",
            "Epoch 97/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 85.9002 - mae: 8.3631 - val_loss: 91.0406 - val_mae: 7.7908\n",
            "Epoch 98/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 87.5481 - mae: 8.3049 - val_loss: 89.9224 - val_mae: 7.7476\n",
            "Epoch 99/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 87.7696 - mae: 8.2705 - val_loss: 89.0334 - val_mae: 7.7207\n",
            "Epoch 100/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 86.2002 - mae: 8.2560 - val_loss: 88.5995 - val_mae: 7.6655\n",
            "Epoch 101/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 86.2439 - mae: 8.2118 - val_loss: 87.9319 - val_mae: 7.6287\n",
            "Epoch 102/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 86.7847 - mae: 8.1493 - val_loss: 86.8972 - val_mae: 7.5899\n",
            "Epoch 103/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 84.3029 - mae: 8.1065 - val_loss: 86.2081 - val_mae: 7.5430\n",
            "Epoch 104/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 84.1816 - mae: 8.0731 - val_loss: 85.3518 - val_mae: 7.5042\n",
            "Epoch 105/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 82.2663 - mae: 8.0341 - val_loss: 84.8285 - val_mae: 7.4611\n",
            "Epoch 106/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 80.8708 - mae: 7.9832 - val_loss: 84.1261 - val_mae: 7.4232\n",
            "Epoch 107/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 80.1379 - mae: 7.9343 - val_loss: 83.0312 - val_mae: 7.3826\n",
            "Epoch 108/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 80.6141 - mae: 7.8992 - val_loss: 82.5026 - val_mae: 7.3416\n",
            "Epoch 109/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 78.0192 - mae: 7.8312 - val_loss: 81.0934 - val_mae: 7.2960\n",
            "Epoch 110/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 81.6447 - mae: 7.7765 - val_loss: 80.1713 - val_mae: 7.2514\n",
            "Epoch 111/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 78.9392 - mae: 7.7936 - val_loss: 79.4546 - val_mae: 7.2147\n",
            "Epoch 112/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 75.6380 - mae: 7.7047 - val_loss: 78.8120 - val_mae: 7.1759\n",
            "Epoch 113/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 74.3596 - mae: 7.6575 - val_loss: 77.7985 - val_mae: 7.1370\n",
            "Epoch 114/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 75.2504 - mae: 7.6317 - val_loss: 77.1321 - val_mae: 7.0924\n",
            "Epoch 115/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 73.0639 - mae: 7.5624 - val_loss: 76.5737 - val_mae: 7.0450\n",
            "Epoch 116/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 73.2407 - mae: 7.5371 - val_loss: 75.3823 - val_mae: 7.0097\n",
            "Epoch 117/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 71.0502 - mae: 7.4793 - val_loss: 74.7914 - val_mae: 6.9668\n",
            "Epoch 118/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 71.6483 - mae: 7.4257 - val_loss: 73.6823 - val_mae: 6.9215\n",
            "Epoch 119/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 69.6420 - mae: 7.3764 - val_loss: 73.0254 - val_mae: 6.8696\n",
            "Epoch 120/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 69.4980 - mae: 7.3174 - val_loss: 71.9681 - val_mae: 6.8256\n",
            "Epoch 121/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 67.6579 - mae: 7.2644 - val_loss: 70.9492 - val_mae: 6.7889\n",
            "Epoch 122/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 70.1224 - mae: 7.2234 - val_loss: 70.0492 - val_mae: 6.7587\n",
            "Epoch 123/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 65.9231 - mae: 7.2024 - val_loss: 69.2019 - val_mae: 6.7023\n",
            "Epoch 124/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 65.3751 - mae: 7.1437 - val_loss: 68.3558 - val_mae: 6.6516\n",
            "Epoch 125/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 66.5812 - mae: 7.0818 - val_loss: 67.2850 - val_mae: 6.6047\n",
            "Epoch 126/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 61.8214 - mae: 7.0254 - val_loss: 66.5067 - val_mae: 6.5527\n",
            "Epoch 127/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 65.4010 - mae: 7.0037 - val_loss: 65.4192 - val_mae: 6.5011\n",
            "Epoch 128/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 61.7390 - mae: 6.9203 - val_loss: 64.2238 - val_mae: 6.4519\n",
            "Epoch 129/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 61.1561 - mae: 6.8736 - val_loss: 64.1641 - val_mae: 6.3911\n",
            "Epoch 130/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 61.2348 - mae: 6.7735 - val_loss: 62.4943 - val_mae: 6.3415\n",
            "Epoch 131/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 62.5344 - mae: 6.7348 - val_loss: 61.0795 - val_mae: 6.2892\n",
            "Epoch 132/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 57.8047 - mae: 6.7008 - val_loss: 60.0033 - val_mae: 6.2263\n",
            "Epoch 133/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 56.6884 - mae: 6.6557 - val_loss: 59.7308 - val_mae: 6.1691\n",
            "Epoch 134/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 57.5505 - mae: 6.5421 - val_loss: 58.9311 - val_mae: 6.1161\n",
            "Epoch 135/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 54.1004 - mae: 6.4703 - val_loss: 57.5592 - val_mae: 6.0661\n",
            "Epoch 136/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 54.3826 - mae: 6.4360 - val_loss: 56.8861 - val_mae: 6.0032\n",
            "Epoch 137/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 54.4105 - mae: 6.4054 - val_loss: 55.7581 - val_mae: 5.9508\n",
            "Epoch 138/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 54.5598 - mae: 6.2934 - val_loss: 54.1792 - val_mae: 5.8991\n",
            "Epoch 139/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 51.7107 - mae: 6.2729 - val_loss: 53.6426 - val_mae: 5.8401\n",
            "Epoch 140/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 51.5066 - mae: 6.1832 - val_loss: 52.2363 - val_mae: 5.7861\n",
            "Epoch 141/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 50.2628 - mae: 6.1387 - val_loss: 51.4325 - val_mae: 5.7421\n",
            "Epoch 142/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 51.4308 - mae: 6.1036 - val_loss: 50.3080 - val_mae: 5.6760\n",
            "Epoch 143/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 47.1136 - mae: 6.0305 - val_loss: 49.4075 - val_mae: 5.6241\n",
            "Epoch 144/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 49.3711 - mae: 5.9890 - val_loss: 48.4991 - val_mae: 5.5712\n",
            "Epoch 145/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 46.1323 - mae: 5.9143 - val_loss: 47.5737 - val_mae: 5.5104\n",
            "Epoch 146/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 44.6089 - mae: 5.8694 - val_loss: 46.7499 - val_mae: 5.4483\n",
            "Epoch 147/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 47.0893 - mae: 5.7620 - val_loss: 45.6966 - val_mae: 5.4064\n",
            "Epoch 148/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 44.9520 - mae: 5.7148 - val_loss: 44.6110 - val_mae: 5.3376\n",
            "Epoch 149/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 43.0607 - mae: 5.6636 - val_loss: 43.8039 - val_mae: 5.2665\n",
            "Epoch 150/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 41.2577 - mae: 5.5672 - val_loss: 42.8795 - val_mae: 5.2050\n",
            "Epoch 151/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 42.6370 - mae: 5.4863 - val_loss: 41.9622 - val_mae: 5.1760\n",
            "Epoch 152/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 39.7028 - mae: 5.4789 - val_loss: 40.8573 - val_mae: 5.1065\n",
            "Epoch 153/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 37.5946 - mae: 5.3965 - val_loss: 39.9434 - val_mae: 5.0267\n",
            "Epoch 154/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 37.5211 - mae: 5.3047 - val_loss: 38.8386 - val_mae: 4.9515\n",
            "Epoch 155/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 36.9997 - mae: 5.2275 - val_loss: 37.6782 - val_mae: 4.9047\n",
            "Epoch 156/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 35.6878 - mae: 5.1736 - val_loss: 36.8469 - val_mae: 4.8279\n",
            "Epoch 157/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 34.7901 - mae: 5.0997 - val_loss: 36.3713 - val_mae: 4.7521\n",
            "Epoch 158/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 35.8835 - mae: 4.9948 - val_loss: 34.8741 - val_mae: 4.6950\n",
            "Epoch 159/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 32.9816 - mae: 4.9676 - val_loss: 34.4550 - val_mae: 4.6077\n",
            "Epoch 160/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 32.7796 - mae: 4.8509 - val_loss: 32.8990 - val_mae: 4.5581\n",
            "Epoch 161/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 31.6589 - mae: 4.8273 - val_loss: 32.0043 - val_mae: 4.5053\n",
            "Epoch 162/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 30.8215 - mae: 4.7475 - val_loss: 31.4020 - val_mae: 4.4178\n",
            "Epoch 163/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 30.6374 - mae: 4.6469 - val_loss: 30.2337 - val_mae: 4.3562\n",
            "Epoch 164/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 31.6197 - mae: 4.6252 - val_loss: 29.5366 - val_mae: 4.2897\n",
            "Epoch 165/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 28.5361 - mae: 4.5254 - val_loss: 29.5676 - val_mae: 4.2182\n",
            "Epoch 166/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 28.9666 - mae: 4.4583 - val_loss: 28.0027 - val_mae: 4.1763\n",
            "Epoch 167/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 27.2971 - mae: 4.3966 - val_loss: 27.8232 - val_mae: 4.0916\n",
            "Epoch 168/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 27.1830 - mae: 4.3270 - val_loss: 26.7361 - val_mae: 4.0315\n",
            "Epoch 169/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 27.3466 - mae: 4.2376 - val_loss: 26.0760 - val_mae: 3.9704\n",
            "Epoch 170/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 24.9715 - mae: 4.2176 - val_loss: 25.6532 - val_mae: 3.9112\n",
            "Epoch 171/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 23.7101 - mae: 4.1335 - val_loss: 25.0851 - val_mae: 3.8454\n",
            "Epoch 172/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 23.0987 - mae: 4.0595 - val_loss: 23.8170 - val_mae: 3.8161\n",
            "Epoch 173/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 23.1789 - mae: 4.0209 - val_loss: 23.2252 - val_mae: 3.7165\n",
            "Epoch 174/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 21.6734 - mae: 3.9458 - val_loss: 22.4523 - val_mae: 3.6568\n",
            "Epoch 175/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 21.5605 - mae: 3.8753 - val_loss: 21.5243 - val_mae: 3.6221\n",
            "Epoch 176/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 21.7433 - mae: 3.8250 - val_loss: 20.8978 - val_mae: 3.5985\n",
            "Epoch 177/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 20.1056 - mae: 3.7553 - val_loss: 20.2351 - val_mae: 3.5160\n",
            "Epoch 178/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 19.2313 - mae: 3.6915 - val_loss: 20.5092 - val_mae: 3.3927\n",
            "Epoch 179/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 21.0068 - mae: 3.5901 - val_loss: 19.0563 - val_mae: 3.4107\n",
            "Epoch 180/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 18.3705 - mae: 3.5648 - val_loss: 18.6298 - val_mae: 3.3902\n",
            "Epoch 181/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 18.1908 - mae: 3.5181 - val_loss: 18.0636 - val_mae: 3.3278\n",
            "Epoch 182/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.8001 - mae: 3.4988 - val_loss: 17.6443 - val_mae: 3.2239\n",
            "Epoch 183/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.6084 - mae: 3.4033 - val_loss: 18.2702 - val_mae: 3.1463\n",
            "Epoch 184/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 17.4417 - mae: 3.3672 - val_loss: 16.7483 - val_mae: 3.1360\n",
            "Epoch 185/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.0792 - mae: 3.3110 - val_loss: 16.7674 - val_mae: 3.0671\n",
            "Epoch 186/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 16.1541 - mae: 3.1930 - val_loss: 15.9673 - val_mae: 3.1505\n",
            "Epoch 187/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 15.2987 - mae: 3.2457 - val_loss: 15.4685 - val_mae: 3.0032\n",
            "Epoch 188/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 14.9557 - mae: 3.1628 - val_loss: 15.2455 - val_mae: 2.9293\n",
            "Epoch 189/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 14.0478 - mae: 3.0688 - val_loss: 14.6320 - val_mae: 2.8765\n",
            "Epoch 190/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.1005 - mae: 3.0280 - val_loss: 14.9778 - val_mae: 2.7891\n",
            "Epoch 191/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 14.0757 - mae: 2.9265 - val_loss: 13.5177 - val_mae: 2.8410\n",
            "Epoch 192/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 12.7316 - mae: 2.9454 - val_loss: 13.3046 - val_mae: 2.7562\n",
            "Epoch 193/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 13.1770 - mae: 2.8403 - val_loss: 13.1101 - val_mae: 2.8123\n",
            "Epoch 194/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.7184 - mae: 2.8516 - val_loss: 13.6171 - val_mae: 2.6452\n",
            "Epoch 195/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.7072 - mae: 2.7851 - val_loss: 12.2685 - val_mae: 2.6524\n",
            "Epoch 196/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 12.0975 - mae: 2.7766 - val_loss: 12.0082 - val_mae: 2.6648\n",
            "Epoch 197/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 11.1366 - mae: 2.6998 - val_loss: 11.6383 - val_mae: 2.6128\n",
            "Epoch 198/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.5411 - mae: 2.6657 - val_loss: 12.0980 - val_mae: 2.5566\n",
            "Epoch 199/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.4849 - mae: 2.5676 - val_loss: 11.1223 - val_mae: 2.5413\n",
            "Epoch 200/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 10.2807 - mae: 2.5414 - val_loss: 10.6087 - val_mae: 2.5300\n",
            "Epoch 201/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 10.0056 - mae: 2.5248 - val_loss: 10.3051 - val_mae: 2.5058\n",
            "Epoch 202/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.1377 - mae: 2.4461 - val_loss: 10.0577 - val_mae: 2.4888\n",
            "Epoch 203/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 9.1224 - mae: 2.4268 - val_loss: 9.7759 - val_mae: 2.4464\n",
            "Epoch 204/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 8.8919 - mae: 2.3899 - val_loss: 9.5982 - val_mae: 2.4198\n",
            "Epoch 205/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.9435 - mae: 2.3051 - val_loss: 9.1917 - val_mae: 2.4059\n",
            "Epoch 206/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 8.2161 - mae: 2.2880 - val_loss: 8.9531 - val_mae: 2.3755\n",
            "Epoch 207/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.6967 - mae: 2.2986 - val_loss: 8.9472 - val_mae: 2.3427\n",
            "Epoch 208/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.4829 - mae: 2.2151 - val_loss: 8.7578 - val_mae: 2.3606\n",
            "Epoch 209/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.5865 - mae: 2.2156 - val_loss: 8.6376 - val_mae: 2.3413\n",
            "Epoch 210/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.8665 - mae: 2.2128 - val_loss: 8.1905 - val_mae: 2.2887\n",
            "Epoch 211/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 7.1922 - mae: 2.1532 - val_loss: 8.0492 - val_mae: 2.2671\n",
            "Epoch 212/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.7794 - mae: 2.1355 - val_loss: 7.9013 - val_mae: 2.2536\n",
            "Epoch 213/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.8694 - mae: 2.0993 - val_loss: 7.7339 - val_mae: 2.2338\n",
            "Epoch 214/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.6360 - mae: 2.1093 - val_loss: 7.7619 - val_mae: 2.2031\n",
            "Epoch 215/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.3008 - mae: 2.0309 - val_loss: 7.9052 - val_mae: 2.1733\n",
            "Epoch 216/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.3771 - mae: 1.9969 - val_loss: 7.3318 - val_mae: 2.1600\n",
            "Epoch 217/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 6.0548 - mae: 2.0283 - val_loss: 7.1841 - val_mae: 2.1452\n",
            "Epoch 218/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6.2483 - mae: 1.9505 - val_loss: 7.1202 - val_mae: 2.1320\n",
            "Epoch 219/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.9271 - mae: 1.9415 - val_loss: 6.9035 - val_mae: 2.1040\n",
            "Epoch 220/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.8771 - mae: 1.9257 - val_loss: 7.1140 - val_mae: 2.0846\n",
            "Epoch 221/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.3866 - mae: 1.8466 - val_loss: 6.9410 - val_mae: 2.0652\n",
            "Epoch 222/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.6201 - mae: 1.8405 - val_loss: 6.7578 - val_mae: 2.0463\n",
            "Epoch 223/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.9240 - mae: 1.7795 - val_loss: 6.5159 - val_mae: 2.0268\n",
            "Epoch 224/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 5.1168 - mae: 1.7792 - val_loss: 7.7150 - val_mae: 2.0358\n",
            "Epoch 225/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 5.1581 - mae: 1.7620 - val_loss: 6.1733 - val_mae: 1.9872\n",
            "Epoch 226/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6288 - mae: 1.7286 - val_loss: 6.0596 - val_mae: 1.9700\n",
            "Epoch 227/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6803 - mae: 1.7286 - val_loss: 6.0411 - val_mae: 1.9680\n",
            "Epoch 228/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.4902 - mae: 1.7374 - val_loss: 5.8309 - val_mae: 1.9305\n",
            "Epoch 229/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.3379 - mae: 1.6838 - val_loss: 6.5036 - val_mae: 1.9274\n",
            "Epoch 230/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.6924 - mae: 1.6548 - val_loss: 5.5862 - val_mae: 1.8903\n",
            "Epoch 231/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.1121 - mae: 1.6813 - val_loss: 5.6206 - val_mae: 1.8716\n",
            "Epoch 232/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0865 - mae: 1.6122 - val_loss: 5.5060 - val_mae: 1.8528\n",
            "Epoch 233/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9249 - mae: 1.6006 - val_loss: 5.8806 - val_mae: 1.8587\n",
            "Epoch 234/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.9113 - mae: 1.5833 - val_loss: 5.3201 - val_mae: 1.8181\n",
            "Epoch 235/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4.0172 - mae: 1.6144 - val_loss: 5.3440 - val_mae: 1.8126\n",
            "Epoch 236/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.8972 - mae: 1.5570 - val_loss: 5.0320 - val_mae: 1.7824\n",
            "Epoch 237/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.9061 - mae: 1.5940 - val_loss: 4.9981 - val_mae: 1.7710\n",
            "Epoch 238/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5834 - mae: 1.5450 - val_loss: 4.9553 - val_mae: 1.7612\n",
            "Epoch 239/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.5797 - mae: 1.5090 - val_loss: 5.7126 - val_mae: 1.8007\n",
            "Epoch 240/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4601 - mae: 1.4945 - val_loss: 4.9425 - val_mae: 1.7441\n",
            "Epoch 241/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.4738 - mae: 1.4718 - val_loss: 4.9888 - val_mae: 1.7404\n",
            "Epoch 242/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.3445 - mae: 1.4828 - val_loss: 4.8379 - val_mae: 1.7223\n",
            "Epoch 243/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.4064 - mae: 1.4668 - val_loss: 4.5294 - val_mae: 1.6861\n",
            "Epoch 244/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.3893 - mae: 1.4641 - val_loss: 4.4512 - val_mae: 1.6724\n",
            "Epoch 245/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3.0589 - mae: 1.4298 - val_loss: 4.8057 - val_mae: 1.6960\n",
            "Epoch 246/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0630 - mae: 1.4219 - val_loss: 4.3744 - val_mae: 1.6500\n",
            "Epoch 247/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.2240 - mae: 1.4246 - val_loss: 4.2100 - val_mae: 1.6271\n",
            "Epoch 248/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1474 - mae: 1.3838 - val_loss: 4.1264 - val_mae: 1.6101\n",
            "Epoch 249/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8375 - mae: 1.3725 - val_loss: 4.3413 - val_mae: 1.6286\n",
            "Epoch 250/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.0075 - mae: 1.3519 - val_loss: 4.2551 - val_mae: 1.6137\n",
            "Epoch 251/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3.1626 - mae: 1.3794 - val_loss: 3.9073 - val_mae: 1.5693\n",
            "Epoch 252/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.9501 - mae: 1.3616 - val_loss: 3.8668 - val_mae: 1.5578\n",
            "Epoch 253/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.8483 - mae: 1.3092 - val_loss: 3.7436 - val_mae: 1.5412\n",
            "Epoch 254/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8441 - mae: 1.3410 - val_loss: 3.7729 - val_mae: 1.5401\n",
            "Epoch 255/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6373 - mae: 1.3096 - val_loss: 3.6305 - val_mae: 1.5172\n",
            "Epoch 256/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6459 - mae: 1.2897 - val_loss: 3.6885 - val_mae: 1.5118\n",
            "Epoch 257/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.8800 - mae: 1.3117 - val_loss: 3.7513 - val_mae: 1.5348\n",
            "Epoch 258/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5466 - mae: 1.2762 - val_loss: 3.6109 - val_mae: 1.5132\n",
            "Epoch 259/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.6645 - mae: 1.2781 - val_loss: 4.1015 - val_mae: 1.5377\n",
            "Epoch 260/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.6613 - mae: 1.2985 - val_loss: 3.3953 - val_mae: 1.4621\n",
            "Epoch 261/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4589 - mae: 1.2597 - val_loss: 3.9087 - val_mae: 1.5367\n",
            "Epoch 262/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5219 - mae: 1.2321 - val_loss: 3.5311 - val_mae: 1.4527\n",
            "Epoch 263/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.5026 - mae: 1.2674 - val_loss: 3.3985 - val_mae: 1.4356\n",
            "Epoch 264/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5390 - mae: 1.2324 - val_loss: 3.2235 - val_mae: 1.4396\n",
            "Epoch 265/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4158 - mae: 1.2507 - val_loss: 3.1453 - val_mae: 1.4280\n",
            "Epoch 266/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.5439 - mae: 1.2847 - val_loss: 3.1333 - val_mae: 1.4221\n",
            "Epoch 267/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4178 - mae: 1.2269 - val_loss: 3.1019 - val_mae: 1.4140\n",
            "Epoch 268/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4725 - mae: 1.2412 - val_loss: 3.4434 - val_mae: 1.4494\n",
            "Epoch 269/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4586 - mae: 1.2371 - val_loss: 3.0290 - val_mae: 1.3937\n",
            "Epoch 270/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3337 - mae: 1.2254 - val_loss: 2.9518 - val_mae: 1.3749\n",
            "Epoch 271/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2789 - mae: 1.2431 - val_loss: 3.1281 - val_mae: 1.3987\n",
            "Epoch 272/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2394 - mae: 1.2001 - val_loss: 3.0731 - val_mae: 1.3530\n",
            "Epoch 273/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2375 - mae: 1.2047 - val_loss: 2.8441 - val_mae: 1.3463\n",
            "Epoch 274/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3026 - mae: 1.2023 - val_loss: 3.2753 - val_mae: 1.3759\n",
            "Epoch 275/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1588 - mae: 1.1920 - val_loss: 2.9226 - val_mae: 1.3533\n",
            "Epoch 276/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.3010 - mae: 1.2031 - val_loss: 2.7153 - val_mae: 1.3233\n",
            "Epoch 277/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2329 - mae: 1.1959 - val_loss: 2.7667 - val_mae: 1.3235\n",
            "Epoch 278/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0819 - mae: 1.1508 - val_loss: 2.6358 - val_mae: 1.3051\n",
            "Epoch 279/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.2757 - mae: 1.2168 - val_loss: 2.6397 - val_mae: 1.2996\n",
            "Epoch 280/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1302 - mae: 1.1815 - val_loss: 2.5692 - val_mae: 1.2867\n",
            "Epoch 281/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.2498 - mae: 1.1739 - val_loss: 2.8057 - val_mae: 1.3062\n",
            "Epoch 282/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0005 - mae: 1.1265 - val_loss: 3.1241 - val_mae: 1.3366\n",
            "Epoch 283/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.4628 - mae: 1.1921 - val_loss: 2.5095 - val_mae: 1.2495\n",
            "Epoch 284/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1101 - mae: 1.1532 - val_loss: 2.8753 - val_mae: 1.2927\n",
            "Epoch 285/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.1244 - mae: 1.1698 - val_loss: 2.4018 - val_mae: 1.2401\n",
            "Epoch 286/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9278 - mae: 1.1231 - val_loss: 2.4231 - val_mae: 1.2283\n",
            "Epoch 287/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0238 - mae: 1.1587 - val_loss: 2.3566 - val_mae: 1.2208\n",
            "Epoch 288/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9274 - mae: 1.1269 - val_loss: 2.3414 - val_mae: 1.2140\n",
            "Epoch 289/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0493 - mae: 1.1718 - val_loss: 2.2620 - val_mae: 1.1972\n",
            "Epoch 290/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9247 - mae: 1.1046 - val_loss: 2.3076 - val_mae: 1.1921\n",
            "Epoch 291/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.1156 - mae: 1.1226 - val_loss: 2.3898 - val_mae: 1.1994\n",
            "Epoch 292/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0442 - mae: 1.1586 - val_loss: 2.1271 - val_mae: 1.1675\n",
            "Epoch 293/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0128 - mae: 1.1542 - val_loss: 2.0891 - val_mae: 1.1654\n",
            "Epoch 294/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8803 - mae: 1.1238 - val_loss: 2.2726 - val_mae: 1.1769\n",
            "Epoch 295/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 2.0526 - mae: 1.1383 - val_loss: 2.0891 - val_mae: 1.1552\n",
            "Epoch 296/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8362 - mae: 1.0986 - val_loss: 2.0850 - val_mae: 1.1427\n",
            "Epoch 297/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9674 - mae: 1.1018 - val_loss: 2.0302 - val_mae: 1.1341\n",
            "Epoch 298/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9949 - mae: 1.0869 - val_loss: 2.0033 - val_mae: 1.1324\n",
            "Epoch 299/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7791 - mae: 1.0688 - val_loss: 1.9481 - val_mae: 1.1229\n",
            "Epoch 300/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8106 - mae: 1.0759 - val_loss: 1.9479 - val_mae: 1.1126\n",
            "Epoch 301/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 2.0352 - mae: 1.1342 - val_loss: 1.9800 - val_mae: 1.1125\n",
            "Epoch 302/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8656 - mae: 1.0911 - val_loss: 1.8821 - val_mae: 1.1041\n",
            "Epoch 303/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7654 - mae: 1.0702 - val_loss: 1.8740 - val_mae: 1.0974\n",
            "Epoch 304/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.9350 - mae: 1.0669 - val_loss: 2.5865 - val_mae: 1.1902\n",
            "Epoch 305/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8073 - mae: 1.0902 - val_loss: 1.8108 - val_mae: 1.0854\n",
            "Epoch 306/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8078 - mae: 1.0378 - val_loss: 1.7816 - val_mae: 1.0760\n",
            "Epoch 307/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8940 - mae: 1.0591 - val_loss: 2.0702 - val_mae: 1.1092\n",
            "Epoch 308/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7783 - mae: 1.0354 - val_loss: 1.7825 - val_mae: 1.0705\n",
            "Epoch 309/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8873 - mae: 1.0637 - val_loss: 1.7202 - val_mae: 1.0586\n",
            "Epoch 310/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8292 - mae: 1.0847 - val_loss: 1.7238 - val_mae: 1.0576\n",
            "Epoch 311/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6876 - mae: 1.0367 - val_loss: 1.7394 - val_mae: 1.0571\n",
            "Epoch 312/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.8046 - mae: 1.0443 - val_loss: 1.6730 - val_mae: 1.0445\n",
            "Epoch 313/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7591 - mae: 1.0257 - val_loss: 2.1496 - val_mae: 1.1265\n",
            "Epoch 314/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8108 - mae: 1.0976 - val_loss: 1.7687 - val_mae: 1.0471\n",
            "Epoch 315/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7474 - mae: 1.0882 - val_loss: 1.6767 - val_mae: 1.0379\n",
            "Epoch 316/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8397 - mae: 1.1034 - val_loss: 1.6417 - val_mae: 1.0321\n",
            "Epoch 317/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6861 - mae: 1.0283 - val_loss: 1.6509 - val_mae: 1.0295\n",
            "Epoch 318/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6264 - mae: 1.0299 - val_loss: 1.6375 - val_mae: 1.0251\n",
            "Epoch 319/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7169 - mae: 1.0368 - val_loss: 1.6679 - val_mae: 1.0260\n",
            "Epoch 320/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9459 - mae: 1.0641 - val_loss: 2.0785 - val_mae: 1.1029\n",
            "Epoch 321/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7422 - mae: 1.0510 - val_loss: 1.5924 - val_mae: 1.0097\n",
            "Epoch 322/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6983 - mae: 1.0452 - val_loss: 2.0424 - val_mae: 1.0950\n",
            "Epoch 323/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6369 - mae: 1.0542 - val_loss: 1.7121 - val_mae: 1.0221\n",
            "Epoch 324/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6549 - mae: 1.0355 - val_loss: 1.7675 - val_mae: 1.0280\n",
            "Epoch 325/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6646 - mae: 1.0349 - val_loss: 1.6788 - val_mae: 1.0135\n",
            "Epoch 326/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8579 - mae: 1.0504 - val_loss: 1.8390 - val_mae: 1.0401\n",
            "Epoch 327/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5365 - mae: 0.9944 - val_loss: 1.6608 - val_mae: 1.0020\n",
            "Epoch 328/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8724 - mae: 1.0523 - val_loss: 1.5000 - val_mae: 0.9828\n",
            "Epoch 329/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.7627 - mae: 1.0750 - val_loss: 1.6098 - val_mae: 0.9973\n",
            "Epoch 330/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6627 - mae: 1.0378 - val_loss: 1.4777 - val_mae: 0.9771\n",
            "Epoch 331/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6911 - mae: 1.0217 - val_loss: 1.5570 - val_mae: 0.9703\n",
            "Epoch 332/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7074 - mae: 1.0304 - val_loss: 1.5674 - val_mae: 0.9862\n",
            "Epoch 333/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7045 - mae: 1.0342 - val_loss: 1.7195 - val_mae: 1.0057\n",
            "Epoch 334/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6801 - mae: 1.0039 - val_loss: 1.9094 - val_mae: 1.0530\n",
            "Epoch 335/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7712 - mae: 1.0920 - val_loss: 1.5080 - val_mae: 0.9556\n",
            "Epoch 336/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6898 - mae: 1.0409 - val_loss: 1.5871 - val_mae: 0.9751\n",
            "Epoch 337/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5975 - mae: 1.0207 - val_loss: 1.4491 - val_mae: 0.9632\n",
            "Epoch 338/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6166 - mae: 0.9795 - val_loss: 2.3183 - val_mae: 1.0983\n",
            "Epoch 339/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.9591 - mae: 1.0776 - val_loss: 1.4897 - val_mae: 0.9515\n",
            "Epoch 340/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7331 - mae: 1.0341 - val_loss: 1.8218 - val_mae: 1.0177\n",
            "Epoch 341/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6847 - mae: 0.9799 - val_loss: 1.4697 - val_mae: 0.9589\n",
            "Epoch 342/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6611 - mae: 1.0328 - val_loss: 1.7867 - val_mae: 1.0095\n",
            "Epoch 343/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.7203 - mae: 1.0597 - val_loss: 1.4387 - val_mae: 0.9435\n",
            "Epoch 344/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6712 - mae: 1.0398 - val_loss: 1.4045 - val_mae: 0.9494\n",
            "Epoch 345/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5086 - mae: 0.9803 - val_loss: 1.6290 - val_mae: 0.9800\n",
            "Epoch 346/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6768 - mae: 1.0134 - val_loss: 1.7901 - val_mae: 1.0089\n",
            "Epoch 347/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8022 - mae: 1.0730 - val_loss: 1.4510 - val_mae: 0.9357\n",
            "Epoch 348/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6066 - mae: 0.9919 - val_loss: 1.5668 - val_mae: 0.9664\n",
            "Epoch 349/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6737 - mae: 1.0182 - val_loss: 1.4913 - val_mae: 0.9401\n",
            "Epoch 350/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5182 - mae: 1.0081 - val_loss: 1.4788 - val_mae: 0.9365\n",
            "Epoch 351/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6111 - mae: 1.0411 - val_loss: 1.8308 - val_mae: 1.0086\n",
            "Epoch 352/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5970 - mae: 1.0221 - val_loss: 1.4302 - val_mae: 0.9380\n",
            "Epoch 353/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6610 - mae: 1.0067 - val_loss: 1.7257 - val_mae: 1.0016\n",
            "Epoch 354/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6578 - mae: 1.0311 - val_loss: 1.4336 - val_mae: 0.9349\n",
            "Epoch 355/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6351 - mae: 1.0222 - val_loss: 1.7137 - val_mae: 0.9970\n",
            "Epoch 356/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5749 - mae: 1.0161 - val_loss: 1.5125 - val_mae: 0.9456\n",
            "Epoch 357/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6164 - mae: 1.0058 - val_loss: 1.3786 - val_mae: 0.9242\n",
            "Epoch 358/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.5709 - mae: 0.9828 - val_loss: 1.3450 - val_mae: 0.9099\n",
            "Epoch 359/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.8442 - mae: 0.9977 - val_loss: 1.7347 - val_mae: 0.9985\n",
            "Epoch 360/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6320 - mae: 1.0430 - val_loss: 1.3548 - val_mae: 0.9193\n",
            "Epoch 361/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5644 - mae: 0.9987 - val_loss: 1.6564 - val_mae: 0.9721\n",
            "Epoch 362/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5363 - mae: 0.9687 - val_loss: 1.3624 - val_mae: 0.9154\n",
            "Epoch 363/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6557 - mae: 1.0351 - val_loss: 1.4990 - val_mae: 0.9379\n",
            "Epoch 364/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4828 - mae: 0.9735 - val_loss: 1.3248 - val_mae: 0.9041\n",
            "Epoch 365/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6772 - mae: 0.9985 - val_loss: 1.3149 - val_mae: 0.9010\n",
            "Epoch 366/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6204 - mae: 1.0297 - val_loss: 1.3216 - val_mae: 0.9030\n",
            "Epoch 367/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.6293 - mae: 0.9817 - val_loss: 1.3012 - val_mae: 0.9029\n",
            "Epoch 368/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5771 - mae: 0.9906 - val_loss: 1.9201 - val_mae: 1.0464\n",
            "Epoch 369/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5805 - mae: 1.0240 - val_loss: 1.3676 - val_mae: 0.9101\n",
            "Epoch 370/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5543 - mae: 1.0085 - val_loss: 1.4523 - val_mae: 0.9248\n",
            "Epoch 371/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6584 - mae: 1.0030 - val_loss: 1.3249 - val_mae: 0.8931\n",
            "Epoch 372/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5715 - mae: 0.9836 - val_loss: 1.3169 - val_mae: 0.8907\n",
            "Epoch 373/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5700 - mae: 1.0130 - val_loss: 1.3634 - val_mae: 0.8913\n",
            "Epoch 374/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4975 - mae: 0.9928 - val_loss: 1.2928 - val_mae: 0.8823\n",
            "Epoch 375/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6226 - mae: 1.0040 - val_loss: 1.5803 - val_mae: 0.9499\n",
            "Epoch 376/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6591 - mae: 1.0221 - val_loss: 1.2668 - val_mae: 0.8882\n",
            "Epoch 377/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5060 - mae: 1.0009 - val_loss: 2.0269 - val_mae: 1.0312\n",
            "Epoch 378/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5877 - mae: 1.0107 - val_loss: 1.2814 - val_mae: 0.8874\n",
            "Epoch 379/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4882 - mae: 0.9844 - val_loss: 1.3949 - val_mae: 0.9055\n",
            "Epoch 380/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6717 - mae: 1.0258 - val_loss: 1.4367 - val_mae: 0.9133\n",
            "Epoch 381/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5260 - mae: 1.0151 - val_loss: 1.3089 - val_mae: 0.8899\n",
            "Epoch 382/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4709 - mae: 0.9750 - val_loss: 2.1132 - val_mae: 1.0458\n",
            "Epoch 383/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6034 - mae: 0.9879 - val_loss: 1.5719 - val_mae: 0.9454\n",
            "Epoch 384/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6883 - mae: 1.0382 - val_loss: 1.2436 - val_mae: 0.8710\n",
            "Epoch 385/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5934 - mae: 1.0110 - val_loss: 1.4871 - val_mae: 0.9223\n",
            "Epoch 386/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6402 - mae: 0.9944 - val_loss: 1.3469 - val_mae: 0.8753\n",
            "Epoch 387/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4288 - mae: 0.9673 - val_loss: 1.5628 - val_mae: 0.9368\n",
            "Epoch 388/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5497 - mae: 1.0008 - val_loss: 1.3435 - val_mae: 0.8777\n",
            "Epoch 389/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6329 - mae: 1.0295 - val_loss: 1.3373 - val_mae: 0.8768\n",
            "Epoch 390/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5492 - mae: 1.0018 - val_loss: 1.2810 - val_mae: 0.8787\n",
            "Epoch 391/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5463 - mae: 0.9856 - val_loss: 1.2740 - val_mae: 0.8578\n",
            "Epoch 392/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6581 - mae: 1.0267 - val_loss: 1.1898 - val_mae: 0.8568\n",
            "Epoch 393/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5071 - mae: 0.9897 - val_loss: 1.4298 - val_mae: 0.9068\n",
            "Epoch 394/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5089 - mae: 0.9830 - val_loss: 1.8283 - val_mae: 1.0109\n",
            "Epoch 395/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5171 - mae: 0.9809 - val_loss: 1.9790 - val_mae: 1.0136\n",
            "Epoch 396/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6396 - mae: 1.0453 - val_loss: 1.3177 - val_mae: 0.8805\n",
            "Epoch 397/1000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.5369 - mae: 0.9703 - val_loss: 1.3227 - val_mae: 0.8698\n",
            "Epoch 398/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4790 - mae: 0.9924 - val_loss: 1.3072 - val_mae: 0.8626\n",
            "Epoch 399/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6113 - mae: 1.0613 - val_loss: 1.2586 - val_mae: 0.8646\n",
            "Epoch 400/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5454 - mae: 1.0279 - val_loss: 1.5899 - val_mae: 0.9338\n",
            "Epoch 401/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5166 - mae: 0.9886 - val_loss: 1.3333 - val_mae: 0.8826\n",
            "Epoch 402/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6418 - mae: 0.9825 - val_loss: 1.1921 - val_mae: 0.8438\n",
            "Epoch 403/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3623 - mae: 0.9645 - val_loss: 1.4072 - val_mae: 0.9002\n",
            "Epoch 404/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6837 - mae: 1.0178 - val_loss: 1.2213 - val_mae: 0.8593\n",
            "Epoch 405/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5347 - mae: 0.9581 - val_loss: 1.7224 - val_mae: 0.9590\n",
            "Epoch 406/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5551 - mae: 0.9599 - val_loss: 1.3727 - val_mae: 0.8817\n",
            "Epoch 407/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6070 - mae: 1.0187 - val_loss: 1.2038 - val_mae: 0.8445\n",
            "Epoch 408/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4141 - mae: 0.9777 - val_loss: 1.6528 - val_mae: 0.9401\n",
            "Epoch 409/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4588 - mae: 0.9677 - val_loss: 1.2722 - val_mae: 0.8644\n",
            "Epoch 410/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4101 - mae: 0.9349 - val_loss: 1.1954 - val_mae: 0.8525\n",
            "Epoch 411/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5904 - mae: 1.0222 - val_loss: 1.1462 - val_mae: 0.8393\n",
            "Epoch 412/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4155 - mae: 0.9634 - val_loss: 1.6142 - val_mae: 0.9326\n",
            "Epoch 413/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4686 - mae: 0.9693 - val_loss: 1.8354 - val_mae: 0.9829\n",
            "Epoch 414/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6733 - mae: 1.0280 - val_loss: 1.1525 - val_mae: 0.8326\n",
            "Epoch 415/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4639 - mae: 0.9931 - val_loss: 1.1557 - val_mae: 0.8454\n",
            "Epoch 416/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5653 - mae: 1.0220 - val_loss: 1.1533 - val_mae: 0.8282\n",
            "Epoch 417/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4271 - mae: 0.9808 - val_loss: 1.2337 - val_mae: 0.8478\n",
            "Epoch 418/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3883 - mae: 0.9775 - val_loss: 1.5853 - val_mae: 0.9272\n",
            "Epoch 419/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5730 - mae: 1.0075 - val_loss: 1.2668 - val_mae: 0.8664\n",
            "Epoch 420/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4748 - mae: 0.9795 - val_loss: 1.2610 - val_mae: 0.8649\n",
            "Epoch 421/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5363 - mae: 1.0054 - val_loss: 1.6441 - val_mae: 0.9402\n",
            "Epoch 422/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4752 - mae: 0.9616 - val_loss: 1.3195 - val_mae: 0.8756\n",
            "Epoch 423/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5968 - mae: 0.9867 - val_loss: 1.4983 - val_mae: 0.9079\n",
            "Epoch 424/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4681 - mae: 0.9619 - val_loss: 1.5279 - val_mae: 0.9126\n",
            "Epoch 425/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4157 - mae: 0.9433 - val_loss: 1.4147 - val_mae: 0.8885\n",
            "Epoch 426/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4769 - mae: 0.9896 - val_loss: 1.4938 - val_mae: 0.9075\n",
            "Epoch 427/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4939 - mae: 0.9868 - val_loss: 1.2426 - val_mae: 0.8476\n",
            "Epoch 428/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5186 - mae: 0.9596 - val_loss: 1.2838 - val_mae: 0.8623\n",
            "Epoch 429/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4866 - mae: 0.9515 - val_loss: 1.3072 - val_mae: 0.8653\n",
            "Epoch 430/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5591 - mae: 0.9788 - val_loss: 1.4034 - val_mae: 0.8866\n",
            "Epoch 431/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5174 - mae: 0.9980 - val_loss: 1.3459 - val_mae: 0.8754\n",
            "Epoch 432/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6029 - mae: 1.0235 - val_loss: 1.4631 - val_mae: 0.9005\n",
            "Epoch 433/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5536 - mae: 1.0126 - val_loss: 1.1179 - val_mae: 0.8271\n",
            "Epoch 434/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5320 - mae: 0.9626 - val_loss: 2.1111 - val_mae: 1.0434\n",
            "Epoch 435/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5886 - mae: 0.9887 - val_loss: 1.1340 - val_mae: 0.8188\n",
            "Epoch 436/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5229 - mae: 0.9739 - val_loss: 1.8071 - val_mae: 0.9761\n",
            "Epoch 437/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5353 - mae: 0.9828 - val_loss: 1.2015 - val_mae: 0.8235\n",
            "Epoch 438/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5615 - mae: 0.9870 - val_loss: 1.1669 - val_mae: 0.8378\n",
            "Epoch 439/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3745 - mae: 0.9401 - val_loss: 1.2032 - val_mae: 0.8423\n",
            "Epoch 440/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3879 - mae: 0.9663 - val_loss: 1.7297 - val_mae: 0.9584\n",
            "Epoch 441/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5210 - mae: 1.0083 - val_loss: 1.1320 - val_mae: 0.8284\n",
            "Epoch 442/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3586 - mae: 0.9192 - val_loss: 2.3217 - val_mae: 1.1223\n",
            "Epoch 443/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4633 - mae: 0.9952 - val_loss: 1.1980 - val_mae: 0.8220\n",
            "Epoch 444/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5447 - mae: 1.0116 - val_loss: 1.1204 - val_mae: 0.8170\n",
            "Epoch 445/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5137 - mae: 0.9818 - val_loss: 1.1791 - val_mae: 0.8205\n",
            "Epoch 446/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4452 - mae: 0.9659 - val_loss: 1.1636 - val_mae: 0.8356\n",
            "Epoch 447/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3342 - mae: 0.9432 - val_loss: 1.6398 - val_mae: 0.9360\n",
            "Epoch 448/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.6176 - mae: 1.0202 - val_loss: 1.1005 - val_mae: 0.8136\n",
            "Epoch 449/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4890 - mae: 0.9803 - val_loss: 1.2703 - val_mae: 0.8550\n",
            "Epoch 450/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3486 - mae: 0.9685 - val_loss: 1.0721 - val_mae: 0.8085\n",
            "Epoch 451/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4947 - mae: 0.9740 - val_loss: 1.1037 - val_mae: 0.8141\n",
            "Epoch 452/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6016 - mae: 1.0299 - val_loss: 1.1099 - val_mae: 0.7974\n",
            "Epoch 453/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4911 - mae: 0.9685 - val_loss: 1.0308 - val_mae: 0.7995\n",
            "Epoch 454/1000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.3560 - mae: 0.9374 - val_loss: 1.1759 - val_mae: 0.8337\n",
            "Epoch 455/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5046 - mae: 0.9942 - val_loss: 1.0749 - val_mae: 0.8078\n",
            "Epoch 456/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3326 - mae: 0.9363 - val_loss: 1.1757 - val_mae: 0.8299\n",
            "Epoch 457/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5628 - mae: 1.0123 - val_loss: 1.1850 - val_mae: 0.8190\n",
            "Epoch 458/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4199 - mae: 0.9552 - val_loss: 1.3553 - val_mae: 0.8644\n",
            "Epoch 459/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5753 - mae: 1.0068 - val_loss: 1.6540 - val_mae: 0.9359\n",
            "Epoch 460/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6642 - mae: 1.0481 - val_loss: 1.5798 - val_mae: 0.9187\n",
            "Epoch 461/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4357 - mae: 0.9829 - val_loss: 1.0975 - val_mae: 0.8150\n",
            "Epoch 462/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3242 - mae: 0.9600 - val_loss: 1.2187 - val_mae: 0.8400\n",
            "Epoch 463/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5349 - mae: 0.9827 - val_loss: 1.0514 - val_mae: 0.7996\n",
            "Epoch 464/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4081 - mae: 0.9627 - val_loss: 1.2768 - val_mae: 0.8494\n",
            "Epoch 465/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4769 - mae: 0.9637 - val_loss: 1.0531 - val_mae: 0.7869\n",
            "Epoch 466/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4593 - mae: 0.9640 - val_loss: 1.9406 - val_mae: 0.9990\n",
            "Epoch 467/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5455 - mae: 0.9809 - val_loss: 1.2216 - val_mae: 0.8233\n",
            "Epoch 468/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4100 - mae: 0.9359 - val_loss: 1.1583 - val_mae: 0.8091\n",
            "Epoch 469/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4743 - mae: 0.9535 - val_loss: 1.0533 - val_mae: 0.7921\n",
            "Epoch 470/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4834 - mae: 0.9922 - val_loss: 1.5518 - val_mae: 0.9108\n",
            "Epoch 471/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3753 - mae: 0.9604 - val_loss: 1.0580 - val_mae: 0.7912\n",
            "Epoch 472/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3244 - mae: 0.9347 - val_loss: 1.4318 - val_mae: 0.8801\n",
            "Epoch 473/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3219 - mae: 0.9481 - val_loss: 1.3780 - val_mae: 0.8670\n",
            "Epoch 474/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4730 - mae: 0.9920 - val_loss: 1.7410 - val_mae: 0.9514\n",
            "Epoch 475/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4882 - mae: 0.9671 - val_loss: 1.2906 - val_mae: 0.8476\n",
            "Epoch 476/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4291 - mae: 0.9720 - val_loss: 1.1046 - val_mae: 0.8061\n",
            "Epoch 477/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5555 - mae: 1.0176 - val_loss: 1.0286 - val_mae: 0.7825\n",
            "Epoch 478/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4618 - mae: 0.9833 - val_loss: 1.3691 - val_mae: 0.8627\n",
            "Epoch 479/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5017 - mae: 0.9917 - val_loss: 1.4544 - val_mae: 0.8794\n",
            "Epoch 480/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3635 - mae: 0.9558 - val_loss: 1.1238 - val_mae: 0.8138\n",
            "Epoch 481/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4368 - mae: 0.9802 - val_loss: 1.0285 - val_mae: 0.7845\n",
            "Epoch 482/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3541 - mae: 0.9518 - val_loss: 1.1309 - val_mae: 0.8020\n",
            "Epoch 483/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4457 - mae: 0.9655 - val_loss: 1.5480 - val_mae: 0.9070\n",
            "Epoch 484/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5510 - mae: 0.9910 - val_loss: 1.0163 - val_mae: 0.7805\n",
            "Epoch 485/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4704 - mae: 0.9857 - val_loss: 1.1860 - val_mae: 0.8222\n",
            "Epoch 486/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3602 - mae: 0.9590 - val_loss: 1.0383 - val_mae: 0.7814\n",
            "Epoch 487/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3444 - mae: 0.9342 - val_loss: 1.1694 - val_mae: 0.8076\n",
            "Epoch 488/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6638 - mae: 0.9934 - val_loss: 1.3799 - val_mae: 0.8597\n",
            "Epoch 489/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4729 - mae: 0.9306 - val_loss: 1.5637 - val_mae: 0.9119\n",
            "Epoch 490/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4069 - mae: 0.9649 - val_loss: 1.0227 - val_mae: 0.7704\n",
            "Epoch 491/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2893 - mae: 0.9247 - val_loss: 1.0566 - val_mae: 0.7715\n",
            "Epoch 492/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5977 - mae: 0.9945 - val_loss: 1.0513 - val_mae: 0.7953\n",
            "Epoch 493/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2725 - mae: 0.9253 - val_loss: 1.6048 - val_mae: 0.9188\n",
            "Epoch 494/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3757 - mae: 0.9407 - val_loss: 1.8980 - val_mae: 0.9848\n",
            "Epoch 495/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4494 - mae: 0.9878 - val_loss: 1.1882 - val_mae: 0.8210\n",
            "Epoch 496/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5022 - mae: 0.9681 - val_loss: 1.5317 - val_mae: 0.9084\n",
            "Epoch 497/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4972 - mae: 1.0080 - val_loss: 1.1267 - val_mae: 0.8092\n",
            "Epoch 498/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3374 - mae: 0.9481 - val_loss: 1.0447 - val_mae: 0.7910\n",
            "Epoch 499/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4312 - mae: 0.9566 - val_loss: 1.4973 - val_mae: 0.8913\n",
            "Epoch 500/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4390 - mae: 0.9624 - val_loss: 0.9452 - val_mae: 0.7532\n",
            "Epoch 501/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5113 - mae: 0.9920 - val_loss: 1.1305 - val_mae: 0.8098\n",
            "Epoch 502/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4378 - mae: 0.9506 - val_loss: 1.6348 - val_mae: 0.9218\n",
            "Epoch 503/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3695 - mae: 0.9547 - val_loss: 1.2182 - val_mae: 0.8198\n",
            "Epoch 504/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4406 - mae: 0.9933 - val_loss: 1.1258 - val_mae: 0.8045\n",
            "Epoch 505/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4724 - mae: 0.9985 - val_loss: 1.0144 - val_mae: 0.7639\n",
            "Epoch 506/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3785 - mae: 0.9582 - val_loss: 1.7222 - val_mae: 0.9418\n",
            "Epoch 507/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3856 - mae: 0.9570 - val_loss: 1.0816 - val_mae: 0.7980\n",
            "Epoch 508/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3777 - mae: 0.9611 - val_loss: 1.5048 - val_mae: 0.9028\n",
            "Epoch 509/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4177 - mae: 0.9592 - val_loss: 1.0074 - val_mae: 0.7641\n",
            "Epoch 510/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3090 - mae: 0.9234 - val_loss: 1.1443 - val_mae: 0.8112\n",
            "Epoch 511/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3765 - mae: 0.9512 - val_loss: 0.9739 - val_mae: 0.7592\n",
            "Epoch 512/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4315 - mae: 0.9780 - val_loss: 1.0945 - val_mae: 0.7972\n",
            "Epoch 513/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3719 - mae: 0.9579 - val_loss: 1.0053 - val_mae: 0.7677\n",
            "Epoch 514/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4830 - mae: 0.9680 - val_loss: 1.0152 - val_mae: 0.7623\n",
            "Epoch 515/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3549 - mae: 0.9438 - val_loss: 0.9941 - val_mae: 0.7541\n",
            "Epoch 516/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3273 - mae: 0.9388 - val_loss: 0.9750 - val_mae: 0.7639\n",
            "Epoch 517/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5259 - mae: 0.9939 - val_loss: 1.0843 - val_mae: 0.7740\n",
            "Epoch 518/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3250 - mae: 0.9359 - val_loss: 2.0085 - val_mae: 1.0077\n",
            "Epoch 519/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3668 - mae: 0.9349 - val_loss: 1.0125 - val_mae: 0.7538\n",
            "Epoch 520/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4534 - mae: 0.9734 - val_loss: 0.9987 - val_mae: 0.7560\n",
            "Epoch 521/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4517 - mae: 0.9703 - val_loss: 1.9467 - val_mae: 0.9928\n",
            "Epoch 522/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4275 - mae: 0.9647 - val_loss: 1.4024 - val_mae: 0.8623\n",
            "Epoch 523/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4865 - mae: 0.9521 - val_loss: 1.0822 - val_mae: 0.7743\n",
            "Epoch 524/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4128 - mae: 0.9873 - val_loss: 1.4551 - val_mae: 0.8751\n",
            "Epoch 525/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4835 - mae: 1.0110 - val_loss: 0.9659 - val_mae: 0.7586\n",
            "Epoch 526/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3419 - mae: 0.9563 - val_loss: 1.7037 - val_mae: 0.9356\n",
            "Epoch 527/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3232 - mae: 0.9360 - val_loss: 1.0055 - val_mae: 0.7788\n",
            "Epoch 528/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5412 - mae: 0.9704 - val_loss: 0.9974 - val_mae: 0.7523\n",
            "Epoch 529/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.6229 - mae: 1.0145 - val_loss: 1.0346 - val_mae: 0.7551\n",
            "Epoch 530/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2855 - mae: 0.9376 - val_loss: 1.2106 - val_mae: 0.8210\n",
            "Epoch 531/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3803 - mae: 0.9300 - val_loss: 1.4709 - val_mae: 0.8878\n",
            "Epoch 532/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4003 - mae: 0.9776 - val_loss: 0.9429 - val_mae: 0.7421\n",
            "Epoch 533/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3879 - mae: 0.9339 - val_loss: 1.0439 - val_mae: 0.7833\n",
            "Epoch 534/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4839 - mae: 0.9622 - val_loss: 1.0363 - val_mae: 0.7733\n",
            "Epoch 535/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3452 - mae: 0.9446 - val_loss: 1.2110 - val_mae: 0.8071\n",
            "Epoch 536/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4229 - mae: 0.9864 - val_loss: 1.1612 - val_mae: 0.8094\n",
            "Epoch 537/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4150 - mae: 0.9367 - val_loss: 0.9780 - val_mae: 0.7460\n",
            "Epoch 538/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2807 - mae: 0.9301 - val_loss: 1.0104 - val_mae: 0.7473\n",
            "Epoch 539/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2492 - mae: 0.9343 - val_loss: 1.1901 - val_mae: 0.7987\n",
            "Epoch 540/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5130 - mae: 0.9971 - val_loss: 1.1260 - val_mae: 0.7852\n",
            "Epoch 541/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3930 - mae: 0.9500 - val_loss: 0.9294 - val_mae: 0.7285\n",
            "Epoch 542/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4308 - mae: 0.9567 - val_loss: 1.1702 - val_mae: 0.8085\n",
            "Epoch 543/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3321 - mae: 0.9463 - val_loss: 1.0809 - val_mae: 0.7875\n",
            "Epoch 544/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3202 - mae: 0.9335 - val_loss: 1.0581 - val_mae: 0.7818\n",
            "Epoch 545/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3643 - mae: 0.9244 - val_loss: 0.9017 - val_mae: 0.7311\n",
            "Epoch 546/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4207 - mae: 0.9701 - val_loss: 0.9904 - val_mae: 0.7694\n",
            "Epoch 547/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3480 - mae: 0.9590 - val_loss: 0.9327 - val_mae: 0.7278\n",
            "Epoch 548/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3950 - mae: 0.9883 - val_loss: 1.1443 - val_mae: 0.8000\n",
            "Epoch 549/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3134 - mae: 0.9257 - val_loss: 1.1250 - val_mae: 0.7943\n",
            "Epoch 550/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3425 - mae: 0.9390 - val_loss: 1.7070 - val_mae: 0.9288\n",
            "Epoch 551/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4352 - mae: 0.9734 - val_loss: 0.9052 - val_mae: 0.7346\n",
            "Epoch 552/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2824 - mae: 0.9427 - val_loss: 0.9877 - val_mae: 0.7399\n",
            "Epoch 553/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4152 - mae: 0.9695 - val_loss: 1.2993 - val_mae: 0.8305\n",
            "Epoch 554/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4137 - mae: 0.9190 - val_loss: 0.9608 - val_mae: 0.7451\n",
            "Epoch 555/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2915 - mae: 0.9239 - val_loss: 2.0353 - val_mae: 1.0115\n",
            "Epoch 556/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4098 - mae: 0.9822 - val_loss: 0.9675 - val_mae: 0.7516\n",
            "Epoch 557/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3296 - mae: 0.9441 - val_loss: 0.9457 - val_mae: 0.7475\n",
            "Epoch 558/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3423 - mae: 0.9292 - val_loss: 1.4436 - val_mae: 0.8752\n",
            "Epoch 559/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6274 - mae: 1.0083 - val_loss: 0.9710 - val_mae: 0.7309\n",
            "Epoch 560/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3419 - mae: 0.9427 - val_loss: 1.1641 - val_mae: 0.7871\n",
            "Epoch 561/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2966 - mae: 0.9212 - val_loss: 1.0524 - val_mae: 0.7561\n",
            "Epoch 562/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4329 - mae: 0.9556 - val_loss: 1.1649 - val_mae: 0.7919\n",
            "Epoch 563/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2919 - mae: 0.9243 - val_loss: 0.9439 - val_mae: 0.7236\n",
            "Epoch 564/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4681 - mae: 0.9954 - val_loss: 0.9012 - val_mae: 0.7334\n",
            "Epoch 565/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4229 - mae: 0.9529 - val_loss: 1.0663 - val_mae: 0.7735\n",
            "Epoch 566/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3405 - mae: 0.9300 - val_loss: 0.9047 - val_mae: 0.7149\n",
            "Epoch 567/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4326 - mae: 0.9585 - val_loss: 0.9165 - val_mae: 0.7213\n",
            "Epoch 568/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4010 - mae: 0.9726 - val_loss: 1.0846 - val_mae: 0.7780\n",
            "Epoch 569/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3511 - mae: 0.9292 - val_loss: 0.9590 - val_mae: 0.7501\n",
            "Epoch 570/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3112 - mae: 0.9190 - val_loss: 0.9717 - val_mae: 0.7267\n",
            "Epoch 571/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4676 - mae: 0.9699 - val_loss: 0.9196 - val_mae: 0.7244\n",
            "Epoch 572/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4428 - mae: 0.9655 - val_loss: 0.9245 - val_mae: 0.7209\n",
            "Epoch 573/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2311 - mae: 0.9011 - val_loss: 1.0731 - val_mae: 0.7593\n",
            "Epoch 574/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3627 - mae: 0.9273 - val_loss: 1.0518 - val_mae: 0.7705\n",
            "Epoch 575/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3296 - mae: 0.9150 - val_loss: 0.9290 - val_mae: 0.7439\n",
            "Epoch 576/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2603 - mae: 0.9175 - val_loss: 0.8828 - val_mae: 0.7219\n",
            "Epoch 577/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4593 - mae: 0.9865 - val_loss: 1.0234 - val_mae: 0.7611\n",
            "Epoch 578/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2636 - mae: 0.9392 - val_loss: 1.0359 - val_mae: 0.7640\n",
            "Epoch 579/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3479 - mae: 0.9429 - val_loss: 1.1418 - val_mae: 0.7875\n",
            "Epoch 580/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2745 - mae: 0.9061 - val_loss: 0.9928 - val_mae: 0.7538\n",
            "Epoch 581/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3720 - mae: 0.9108 - val_loss: 1.6168 - val_mae: 0.9060\n",
            "Epoch 582/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3501 - mae: 0.9453 - val_loss: 1.3234 - val_mae: 0.8333\n",
            "Epoch 583/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3404 - mae: 0.9367 - val_loss: 0.8965 - val_mae: 0.7273\n",
            "Epoch 584/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3399 - mae: 0.9452 - val_loss: 0.9163 - val_mae: 0.7400\n",
            "Epoch 585/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4813 - mae: 0.9741 - val_loss: 0.9190 - val_mae: 0.7249\n",
            "Epoch 586/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3336 - mae: 0.9331 - val_loss: 1.0169 - val_mae: 0.7625\n",
            "Epoch 587/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3427 - mae: 0.9338 - val_loss: 0.9535 - val_mae: 0.7208\n",
            "Epoch 588/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3230 - mae: 0.9585 - val_loss: 0.9888 - val_mae: 0.7566\n",
            "Epoch 589/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2460 - mae: 0.9192 - val_loss: 0.9441 - val_mae: 0.7371\n",
            "Epoch 590/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3410 - mae: 0.9443 - val_loss: 0.9321 - val_mae: 0.7358\n",
            "Epoch 591/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3321 - mae: 0.9373 - val_loss: 1.3175 - val_mae: 0.8292\n",
            "Epoch 592/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4018 - mae: 0.9488 - val_loss: 0.9271 - val_mae: 0.7132\n",
            "Epoch 593/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2576 - mae: 0.9179 - val_loss: 0.9506 - val_mae: 0.7191\n",
            "Epoch 594/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4881 - mae: 0.9952 - val_loss: 1.0177 - val_mae: 0.7640\n",
            "Epoch 595/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.5037 - mae: 0.9372 - val_loss: 1.2307 - val_mae: 0.8107\n",
            "Epoch 596/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3679 - mae: 0.9403 - val_loss: 1.1708 - val_mae: 0.7956\n",
            "Epoch 597/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3498 - mae: 0.9419 - val_loss: 1.0689 - val_mae: 0.7707\n",
            "Epoch 598/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3633 - mae: 0.9485 - val_loss: 1.2497 - val_mae: 0.8111\n",
            "Epoch 599/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4732 - mae: 0.9578 - val_loss: 1.0371 - val_mae: 0.7442\n",
            "Epoch 600/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2928 - mae: 0.9021 - val_loss: 0.9229 - val_mae: 0.7104\n",
            "Epoch 601/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4192 - mae: 0.9546 - val_loss: 0.9592 - val_mae: 0.7435\n",
            "Epoch 602/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2376 - mae: 0.9299 - val_loss: 1.0878 - val_mae: 0.7749\n",
            "Epoch 603/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.5565 - mae: 0.9919 - val_loss: 0.9153 - val_mae: 0.7104\n",
            "Epoch 604/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2590 - mae: 0.9176 - val_loss: 0.9145 - val_mae: 0.7081\n",
            "Epoch 605/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2780 - mae: 0.9502 - val_loss: 0.8808 - val_mae: 0.7134\n",
            "Epoch 606/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2920 - mae: 0.9324 - val_loss: 0.8975 - val_mae: 0.7040\n",
            "Epoch 607/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.6462 - mae: 1.0132 - val_loss: 0.9805 - val_mae: 0.7269\n",
            "Epoch 608/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3238 - mae: 0.9434 - val_loss: 1.5035 - val_mae: 0.8764\n",
            "Epoch 609/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4588 - mae: 0.9252 - val_loss: 1.1152 - val_mae: 0.7636\n",
            "Epoch 610/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3728 - mae: 0.9322 - val_loss: 0.9085 - val_mae: 0.7109\n",
            "Epoch 611/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3865 - mae: 0.9409 - val_loss: 0.9770 - val_mae: 0.7440\n",
            "Epoch 612/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5161 - mae: 1.0081 - val_loss: 1.2591 - val_mae: 0.8156\n",
            "Epoch 613/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3286 - mae: 0.9344 - val_loss: 0.9498 - val_mae: 0.7430\n",
            "Epoch 614/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2892 - mae: 0.9361 - val_loss: 1.1952 - val_mae: 0.7982\n",
            "Epoch 615/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3791 - mae: 0.9503 - val_loss: 1.3189 - val_mae: 0.8297\n",
            "Epoch 616/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2417 - mae: 0.9192 - val_loss: 1.1251 - val_mae: 0.7834\n",
            "Epoch 617/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3492 - mae: 0.9577 - val_loss: 1.1359 - val_mae: 0.7708\n",
            "Epoch 618/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2901 - mae: 0.9334 - val_loss: 0.8927 - val_mae: 0.7292\n",
            "Epoch 619/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3643 - mae: 0.9513 - val_loss: 0.9414 - val_mae: 0.7376\n",
            "Epoch 620/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2308 - mae: 0.9044 - val_loss: 1.0606 - val_mae: 0.7525\n",
            "Epoch 621/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3727 - mae: 0.9134 - val_loss: 1.0316 - val_mae: 0.7605\n",
            "Epoch 622/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3570 - mae: 0.9580 - val_loss: 0.9362 - val_mae: 0.7402\n",
            "Epoch 623/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3081 - mae: 0.9160 - val_loss: 0.8707 - val_mae: 0.7014\n",
            "Epoch 624/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2902 - mae: 0.8984 - val_loss: 1.2563 - val_mae: 0.8109\n",
            "Epoch 625/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3881 - mae: 0.9573 - val_loss: 0.9566 - val_mae: 0.7163\n",
            "Epoch 626/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4071 - mae: 0.9544 - val_loss: 0.8794 - val_mae: 0.7109\n",
            "Epoch 627/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3599 - mae: 0.9333 - val_loss: 1.3009 - val_mae: 0.8229\n",
            "Epoch 628/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3390 - mae: 0.9622 - val_loss: 1.8989 - val_mae: 0.9759\n",
            "Epoch 629/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4655 - mae: 0.9928 - val_loss: 0.9011 - val_mae: 0.7330\n",
            "Epoch 630/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3347 - mae: 0.9583 - val_loss: 0.8679 - val_mae: 0.7104\n",
            "Epoch 631/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2881 - mae: 0.9190 - val_loss: 1.1349 - val_mae: 0.7688\n",
            "Epoch 632/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3454 - mae: 0.9607 - val_loss: 1.0745 - val_mae: 0.7698\n",
            "Epoch 633/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4271 - mae: 0.9575 - val_loss: 1.0223 - val_mae: 0.7361\n",
            "Epoch 634/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2798 - mae: 0.9156 - val_loss: 0.9367 - val_mae: 0.7353\n",
            "Epoch 635/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4364 - mae: 0.9298 - val_loss: 0.9284 - val_mae: 0.7141\n",
            "Epoch 636/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4557 - mae: 0.9707 - val_loss: 0.9045 - val_mae: 0.7058\n",
            "Epoch 637/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2642 - mae: 0.9155 - val_loss: 0.9750 - val_mae: 0.7457\n",
            "Epoch 638/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3942 - mae: 0.9341 - val_loss: 1.3225 - val_mae: 0.8385\n",
            "Epoch 639/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4277 - mae: 0.9741 - val_loss: 0.9022 - val_mae: 0.7262\n",
            "Epoch 640/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4219 - mae: 0.9325 - val_loss: 0.9622 - val_mae: 0.7176\n",
            "Epoch 641/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3173 - mae: 0.9433 - val_loss: 0.9422 - val_mae: 0.7413\n",
            "Epoch 642/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4263 - mae: 0.9355 - val_loss: 0.9434 - val_mae: 0.7138\n",
            "Epoch 643/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3624 - mae: 0.9489 - val_loss: 0.9498 - val_mae: 0.7421\n",
            "Epoch 644/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2732 - mae: 0.9340 - val_loss: 0.8965 - val_mae: 0.7244\n",
            "Epoch 645/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4109 - mae: 0.9564 - val_loss: 0.8953 - val_mae: 0.7021\n",
            "Epoch 646/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2679 - mae: 0.9178 - val_loss: 1.0622 - val_mae: 0.7678\n",
            "Epoch 647/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3972 - mae: 0.9581 - val_loss: 0.8707 - val_mae: 0.7032\n",
            "Epoch 648/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3292 - mae: 0.9441 - val_loss: 0.8867 - val_mae: 0.7093\n",
            "Epoch 649/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3727 - mae: 0.9659 - val_loss: 1.0395 - val_mae: 0.7577\n",
            "Epoch 650/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2749 - mae: 0.9301 - val_loss: 0.8755 - val_mae: 0.6969\n",
            "Epoch 651/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3613 - mae: 0.9663 - val_loss: 0.8835 - val_mae: 0.7218\n",
            "Epoch 652/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2875 - mae: 0.9271 - val_loss: 1.4509 - val_mae: 0.8628\n",
            "Epoch 653/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3393 - mae: 0.9350 - val_loss: 0.8599 - val_mae: 0.7182\n",
            "Epoch 654/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3265 - mae: 0.9326 - val_loss: 1.1030 - val_mae: 0.7668\n",
            "Epoch 655/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3622 - mae: 0.9364 - val_loss: 0.8515 - val_mae: 0.7135\n",
            "Epoch 656/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2028 - mae: 0.9179 - val_loss: 0.8113 - val_mae: 0.6830\n",
            "Epoch 657/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2894 - mae: 0.9355 - val_loss: 0.9479 - val_mae: 0.7199\n",
            "Epoch 658/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2804 - mae: 0.8966 - val_loss: 1.1580 - val_mae: 0.7840\n",
            "Epoch 659/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3120 - mae: 0.9239 - val_loss: 0.8895 - val_mae: 0.7195\n",
            "Epoch 660/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4530 - mae: 0.9483 - val_loss: 0.9025 - val_mae: 0.7271\n",
            "Epoch 661/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3356 - mae: 0.9299 - val_loss: 1.1155 - val_mae: 0.7645\n",
            "Epoch 662/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2175 - mae: 0.8876 - val_loss: 0.8572 - val_mae: 0.6881\n",
            "Epoch 663/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2446 - mae: 0.9040 - val_loss: 0.8139 - val_mae: 0.6838\n",
            "Epoch 664/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3703 - mae: 0.9363 - val_loss: 1.1803 - val_mae: 0.7923\n",
            "Epoch 665/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3097 - mae: 0.9101 - val_loss: 1.3341 - val_mae: 0.8318\n",
            "Epoch 666/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3408 - mae: 0.9278 - val_loss: 0.8579 - val_mae: 0.6891\n",
            "Epoch 667/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2561 - mae: 0.9356 - val_loss: 0.9723 - val_mae: 0.7429\n",
            "Epoch 668/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3970 - mae: 0.9355 - val_loss: 0.9122 - val_mae: 0.7027\n",
            "Epoch 669/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2956 - mae: 0.9312 - val_loss: 1.0223 - val_mae: 0.7553\n",
            "Epoch 670/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3416 - mae: 0.9087 - val_loss: 2.4923 - val_mae: 1.1217\n",
            "Epoch 671/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.4189 - mae: 0.9317 - val_loss: 0.9909 - val_mae: 0.7482\n",
            "Epoch 672/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.3272 - mae: 0.9307 - val_loss: 0.8411 - val_mae: 0.6987\n",
            "Epoch 673/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3396 - mae: 0.9364 - val_loss: 1.0544 - val_mae: 0.7598\n",
            "Epoch 674/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3690 - mae: 0.9563 - val_loss: 0.8410 - val_mae: 0.6842\n",
            "Epoch 675/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2890 - mae: 0.9216 - val_loss: 1.2998 - val_mae: 0.8318\n",
            "Epoch 676/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.4765 - mae: 0.9715 - val_loss: 0.8409 - val_mae: 0.6834\n",
            "Epoch 677/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.2790 - mae: 0.9193 - val_loss: 1.2438 - val_mae: 0.8091\n",
            "Epoch 678/1000\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.2867 - mae: 0.8988 - val_loss: 1.6137 - val_mae: 0.9095\n",
            "Epoch 679/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3225 - mae: 0.9464 - val_loss: 0.8768 - val_mae: 0.7204\n",
            "Epoch 680/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.3602 - mae: 0.9457 - val_loss: 0.7959 - val_mae: 0.6874\n",
            "Epoch 681/1000\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 1.2736 - mae: 0.9352 - val_loss: 0.8344 - val_mae: 0.6829\n",
            "Epoch 682/1000\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 1.3964 - mae: 0.9371 - val_loss: 1.2341 - val_mae: 0.8079\n",
            "Epoch 683/1000\n",
            "1/8 [==>...........................] - ETA: 0s - loss: 2.9001 - mae: 1.2973"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h86FEo80XhW",
        "colab_type": "text"
      },
      "source": [
        "## Convert the Tensorflow Model to Tensorflow Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egny1KLL0Wm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()\n",
        "open(\"model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFc5JmXo41H1",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViQ7W8d-7PXK",
        "colab_type": "text"
      },
      "source": [
        "### Predict with Tensorflow Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkGzRSdA478s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the model to make predictions from our test data\n",
        "\n",
        "############################################################\n",
        "#@markdown How to use the model to predict the result with the test data (`x_test`) and save the result in a variable `predictions`?\n",
        "script = \"predictions = tflite_model.predict(x_test)\" #@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeH5sWiu7RhT",
        "colab_type": "text"
      },
      "source": [
        "### Predict with Tensorflow Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET8_k-vvwop0",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Use the Tensorflow lite model to make interfences from our test data\n",
        "#@markdown Please choose and fill in correct code statements from one of the following:\n",
        "#@markdown 1. interpreter.invoke() \n",
        "#@markdown 2. interpreter_input().fill(x_test[i])\n",
        "#@markdown 3. interpreter = tf.lite.Interpreter('model.tflite')\n",
        "#@markdown 4. interpreter_predictions[i] = interpreter_output()[0]\n",
        "#@markdown 5. interpreter_output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
        "#@markdown 6. interpreter_input = interpreter.tensor(interpreter.get_input_details()[0][\"index\"])\n",
        "\n",
        "############################################################\n",
        "# Instantiate an interpreter for the TFLite model\n",
        "#@markdown Which is the statement to instantiate an interpreter with a TFLite Model named `model.tflite`?\n",
        "script_1 = \"interpreter = tf.lite.Interpreter('model.tflite')\" #@param {type:\"string\"}\n",
        "exec(script_1)\n",
        "############################################################\n",
        "\n",
        "# Allocate memory for the model\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "############################################################\n",
        "# Get the input tensors so we can feed in values \n",
        "#@markdown Which is the statement to get input sensors?\n",
        "script_2 = \"interpreter_input = interpreter.tensor(interpreter.get_input_details()[0][\\\"index\\\"])\" #@param {type:\"string\"}\n",
        "exec(script_2)\n",
        "############################################################\n",
        "\n",
        "############################################################\n",
        "# Get the output tensors so we can get the results\n",
        "#@markdown Which is the statement to get output sensors?\n",
        "script_3 = \"interpreter_output = interpreter.tensor(interpreter.get_output_details()[0][\\\"index\\\"])\" #@param {type:\"string\"}\n",
        "exec(script_3)\n",
        "############################################################\n",
        "\n",
        "# Create arrays to store the results\n",
        "interpreter_predictions = np.empty(x_test.size)\n",
        "\n",
        "# Run each model's interpreter for each value and store the results in arrays\n",
        "for i in range(x_test.size):\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to fill the input of the interpreter with `x_test[i]`?\n",
        "  script_4 = \"interpreter_input().fill(x_test[i])\" #@param {type:\"string\"}\n",
        "  exec(script_4)\n",
        "  ############################################################\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to invoke the interpreter?\n",
        "  script_5 = \"interpreter.invoke()\" #@param {type:\"string\"}\n",
        "  exec(script_5)\n",
        "  ############################################################\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to get the output from the interpreter and save the output in `interpreter_predictions[i]`?\n",
        "  script_6 = \"interpreter_predictions[i] = interpreter_output()[0]\"#@param {type:\"string\"}\n",
        "  exec(script_6)\n",
        "  ############################################################\n",
        "\n",
        "\n",
        "# Make the shape of the y_test be the same as the predictions\n",
        "y_test = np.reshape(y_test, predictions.shape)\n",
        "# Make the shape of the interpreter_predictions be the same as the predictions\n",
        "interpreter_predictions = np.reshape(interpreter_predictions, predictions.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciEdnWpc1rR5",
        "colab_type": "text"
      },
      "source": [
        "## Plot the Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svBsN_bVu1HL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.clf()\n",
        "plt.title('Test data predicted vs actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_test, predictions, 'r.', label='Predicted (tensorflow)')\n",
        "############################################################\n",
        "#@markdown Please write the statement to plot the outputs in green dots with a label `Predicted (tflite)` from the interpreter.\n",
        "script = \"plt.plot(x_test, interpreter_predictions, 'g.', label='Predicted (tflite)')\"#@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}